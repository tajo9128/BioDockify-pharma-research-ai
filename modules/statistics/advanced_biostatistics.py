"""Advanced Biostatistics Module

Provides comprehensive biostatistical analysis for pharmaceutical research
including regression models, meta-analysis, and equivalence testing.

Complies with:
- Good Laboratory Practice (GLP)
- Good Clinical Practice (GCP)
- FDA Statistical Guidance for Clinical Trials
- EMA Guideline on Statistical Principles for Clinical Trials
- ICH E9 Statistical Principles for Clinical Trials
"""

import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf
import warnings
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
import json

warnings.filterwarnings('ignore')

class AdvancedBiostatistics:
    """Advanced biostatistical analysis for pharmaceutical research"""

    def __init__(self, alpha: float = 0.05):
        self.alpha = alpha
        self.analysis_history = []

    def logistic_regression(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], covariates: Optional[List[str]] = None) -> Dict[str, Any]:
        """Binary logistic regression with odds ratios"""
        results = {"analysis_type": "Binary Logistic Regression", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "model_summary": {}, "odds_ratios": {}, "confidence_intervals": {}, "goodness_of_fit": {},
                   "diagnostics": {}, "assumptions_checked": {}, "interpretation": {}, "recommendations": []}
        data = df.copy()
        if isinstance(x_vars, str):
            x_vars = [x_vars]
        if covariates is None:
            covariates = []
        all_vars = x_vars + covariates
        formula = f"{y_var} ~ " + " + ".join(all_vars)
        try:
            model = smf.logit(formula, data=data).fit(disp=0)
            params, conf_int, pvalues = model.params, model.conf_int(alpha=self.alpha), model.pvalues
            odds_ratios, or_ci_lower, or_ci_upper = np.exp(params), np.exp(conf_int[0]), np.exp(conf_int[1])
            for var in all_vars:
                results["model_summary"][var] = {"coefficient": float(params[var]), "standard_error": float(model.bse[var]),
                    "z_statistic": float(model.tvalues[var]), "p_value": float(pvalues[var])}
                results["odds_ratios"][var] = {"odds_ratio": float(odds_ratios[var]), "ci_lower": float(or_ci_lower[var]),
                    "ci_upper": float(or_ci_upper[var]), "significant": pvalues[var] < self.alpha}
                results["confidence_intervals"][var] = {"log_scale_lower": float(conf_int[0][var]), "log_scale_upper": float(conf_int[1][var])}
            results["goodness_of_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic),
                "pseudo_r2_mcfadden": float(model.prsquared), "pseudo_r2_nagelkerke": float((1 - np.exp((model.llnull - model.llf) * (2 / len(data)))) / (1 - np.exp(model.llnull * (2 / len(data)))))}
            results["diagnostics"] = {"deviance": float(model.deviance), "pearson_chi2": float(model.pearson_chi2),
                "degrees_of_freedom": int(model.df_model), "n_observations": int(len(data))}
            results["assumptions_checked"] = {"linearity_logit": "Check via Box-Tidwell test", "independence_of_errors": "Assumed",
                "multicollinearity": "Recommend VIF calculation", "outliers": "Recommend deviance residual analysis",
                "sample_size": f"Events per variable: {data[y_var].sum() / len(all_vars):.2f} (>10 recommended)"}
            results["interpretation"] = self._interpret_logistic_regression(results["odds_ratios"], all_vars)
            results["recommendations"] = self._generate_logistic_recommendations(results, len(data), data[y_var].sum(), len(all_vars))
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error fitting model: {e}")
        return results

    def _interpret_logistic_regression(self, odds_ratios: Dict, variables: List[str]) -> Dict[str, str]:
        interpretations = {"overall_interpretation": "", "variable_interpretations": {}, "clinical_significance": ""}
        for var in variables:
            or_val, ci_low, ci_high, is_sig = odds_ratios[var]["odds_ratio"], odds_ratios[var]["ci_lower"], odds_ratios[var]["ci_upper"], odds_ratios[var]["significant"]
            direction = "increases" if or_val > 1 else "decreases" if or_val < 1 else "has no effect on"
            magnitude = f"{or_val:.2f} times" if or_val > 0 else "no change"
            sig_text = "statistically significant" if is_sig else "not statistically significant"
            interpretations["variable_interpretations"][var] = f"{var} {direction} the odds of the outcome by {magnitude} (OR={or_val:.3f}, 95% CI: {ci_low:.3f}-{ci_high:.3f}). This effect is {sig_text}."
        interpretations["overall_interpretation"] = "Logistic regression with odds ratios representing multiplicative change in odds per unit increase in predictor."
        interpretations["clinical_significance"] = "Clinical significance depends on effect size magnitude and CI width. Consider clinical relevance alongside statistical significance."
        return interpretations

    def _generate_logistic_recommendations(self, results: Dict, n_obs: int, n_events: int, n_vars: int) -> List[str]:
        recommendations = []
        epv = n_events / n_vars if n_vars > 0 else 0
        if epv < 10:
            recommendations.append(f"Events per variable (EPV = {epv:.2f}) below 10. Consider reducing predictors or increasing sample size.")
        pseudo_r2 = results["goodness_of_fit"].get("pseudo_r2_nagelkerke", 0)
        if pseudo_r2 < 0.1:
            recommendations.append(f"Low pseudo R² ({pseudo_r2:.3f}). Model explains limited variance.")
        elif pseudo_r2 > 0.8:
            recommendations.append(f"Very high pseudo R² ({pseudo_r2:.3f}). Check for overfitting.")
        return recommendations

    def multinomial_logistic_regression(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], reference_category: Optional[Union[int, str]] = None) -> Dict[str, Any]:
        """Multinomial logistic regression for >2 categories"""
        results = {"analysis_type": "Multinomial Logistic Regression", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "model_summary": {}, "relative_risk_ratios": {}, "confidence_intervals": {}, "goodness_of_fit": {},
                   "interpretation": {}, "recommendations": []}
        data, x_vars = df.copy(), [x_vars] if isinstance(x_vars, str) else x_vars
        data[y_var] = data[y_var].astype("category")
        categories = data[y_var].cat.categories.tolist()
        reference_category = categories[0] if reference_category is None else reference_category
        try:
            formula = f"{y_var} ~ " + " + ".join(x_vars)
            model = smf.mnlogit(formula, data=data).fit(disp=0)
            outcome_categories = [c for c in categories if c != reference_category]
            params, conf_int, pvalues = model.params, model.conf_int(alpha=self.alpha), model.pvalues
            for outcome in outcome_categories:
                results["model_summary"][outcome], results["relative_risk_ratios"][outcome], results["confidence_intervals"][outcome] = {}, {}, {}
                for var in x_vars:
                    coef_key, coef, se, pval = (outcome, var), float(params.loc[coef_key]), float(model.bse.loc[coef_key]), float(pvalues.loc[coef_key])
                    rrr, ci_lower, ci_upper = np.exp(coef), np.exp(float(conf_int[0].loc[coef_key])), np.exp(float(conf_int[1].loc[coef_key]))
                    results["model_summary"][outcome][var] = {"coefficient": coef, "standard_error": se, "z_statistic": coef/se if se > 0 else 0, "p_value": pval}
                    results["relative_risk_ratios"][outcome][var] = {"relative_risk_ratio": rrr, "ci_lower": ci_lower, "ci_upper": ci_upper, "significant": pval < self.alpha}
                    results["confidence_intervals"][outcome][var] = {"log_scale_lower": float(conf_int[0].loc[coef_key]), "log_scale_upper": float(conf_int[1].loc[coef_key])}
            results["goodness_of_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic), "n_observations": int(len(data)), "n_categories": len(categories), "reference_category": str(reference_category)}
            results["interpretation"] = self._interpret_multinomial_regression(results["relative_risk_ratios"], x_vars, outcome_categories, reference_category)
            results["recommendations"] = self._generate_multinomial_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_multinomial_regression(self, rrrs: Dict, variables: List[str], outcomes: List, reference: Any) -> Dict[str, str]:
        interpretations = {"overall_interpretation": f"Multinomial logistic regression comparing outcomes vs reference '{reference}'. RRR indicates multiplicative change in relative risk.", "outcome_interpretations": {}, "clinical_significance": "RRR > 1 higher relative risk, RRR < 1 lower relative risk."}
        for outcome in outcomes:
            interpretations["outcome_interpretations"][outcome] = {}
            for var in variables:
                rrr_val, ci_low, ci_high, is_sig = rrrs[outcome][var]["relative_risk_ratio"], rrrs[outcome][var]["ci_lower"], rrrs[outcome][var]["ci_upper"], rrrs[outcome][var]["significant"]
                direction = "increases" if rrr_val > 1 else "decreases" if rrr_val < 1 else "has no effect on"
                interpretations["outcome_interpretations"][outcome][var] = f"{var} {direction} relative risk of {outcome} vs {reference} by {rrr_val:.3f}x (RRR={rrr_val:.3f}, 95% CI: {ci_low:.3f}-{ci_high:.3f}). Effect is {'statistically significant' if is_sig else 'not statistically significant'}."
        return interpretations

    def _generate_multinomial_recommendations(self, results: Dict) -> List[str]:
        n_obs, n_cats = results["goodness_of_fit"]["n_observations"], results["goodness_of_fit"]["n_categories"]
        return [] if n_obs / n_cats >= 20 else [f"Low observations per category ({n_obs/n_cats:.1f}). May lead to unstable estimates."]

    def poisson_regression(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], covariates: Optional[List[str]] = None, offset: Optional[str] = None) -> Dict[str, Any]:
        """Poisson regression for count data"""
        results = {"analysis_type": "Poisson Regression", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "model_summary": {}, "incidence_rate_ratios": {}, "confidence_intervals": {}, "goodness_of_fit": {},
                   "overdispersion_test": {}, "diagnostics": {}, "interpretation": {}, "recommendations": []}
        data = df.copy()
        if isinstance(x_vars, str):
            x_vars = [x_vars]
        if covariates is None:
            covariates = []
        all_vars, formula = x_vars + covariates, f"{y_var} ~ " + " + ".join(x_vars + covariates)
        if offset:
            formula += f" + offset({offset})"
        try:
            model = smf.glm(formula, data=data, family=sm.families.Poisson()).fit()
            params, conf_int, pvalues = model.params, model.conf_int(alpha=self.alpha), model.pvalues
            irr, irr_ci_lower, irr_ci_upper = np.exp(params), np.exp(conf_int[0]), np.exp(conf_int[1])
            for var in all_vars:
                results["model_summary"][var] = {"coefficient": float(params[var]), "standard_error": float(model.bse[var]),
                    "z_statistic": float(model.tvalues[var]), "p_value": float(pvalues[var])}
                results["incidence_rate_ratios"][var] = {"irr": float(irr[var]), "ci_lower": float(irr_ci_lower[var]),
                    "ci_upper": float(irr_ci_upper[var]), "significant": pvalues[var] < self.alpha}
                results["confidence_intervals"][var] = {"log_scale_lower": float(conf_int[0][var]), "log_scale_upper": float(conf_int[1][var])}
            results["goodness_of_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic),
                "deviance": float(model.deviance), "pearson_chi2": float(model.pearson_chi2), "df_resid": int(model.df_resid)}
            pearson_chi2, df_resid = model.pearson_chi2, model.df_resid
            dispersion_ratio, p_overdispersion = pearson_chi2 / df_resid, 1 - stats.chi2.cdf(pearson_chi2, df_resid)
            results["overdispersion_test"] = {"pearson_chi2": float(pearson_chi2), "df_residual": int(df_resid),
                "dispersion_ratio": float(dispersion_ratio), "p_value": float(p_overdispersion), "overdispersion_present": dispersion_ratio > 1.5}
            results["diagnostics"] = {"mean_response": float(data[y_var].mean()), "variance_response": float(data[y_var].var()),
                "variance_mean_ratio": float(data[y_var].var() / data[y_var].mean()) if data[y_var].mean() > 0 else None}
            results["interpretation"] = self._interpret_poisson_regression(results["incidence_rate_ratios"], all_vars, results["overdispersion_test"])
            results["recommendations"] = self._generate_poisson_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_poisson_regression(self, irrs: Dict, variables: List[str], overdispersion: Dict) -> Dict[str, str]:
        interpretations = {"overall_interpretation": "Poisson regression with log link for count data. IRR represents multiplicative change in expected count.", "variable_interpretations": {}, "overdispersion_interpretation": "", "clinical_significance": "IRR > 1 higher expected count, IRR < 1 lower expected count."}
        for var in variables:
            irr_val, is_sig = irrs[var]["irr"], irrs[var]["significant"]
            direction = "increases" if irr_val > 1 else "decreases" if irr_val < 1 else "has no effect on"
            sig_text = "statistically significant" if is_sig else "not statistically significant"
            interpretations["variable_interpretations"][var] = f"{var} {direction} expected count by {irr_val:.3f} times (IRR={irr_val:.3f}, 95% CI: {irrs[var]['ci_lower']:.3f}-{irrs[var]['ci_upper']:.3f}). Effect is {sig_text}."
        interpretations["overdispersion_interpretation"] = f"{'Overdispersion detected' if overdispersion['overdispersion_present'] else 'No significant overdispersion'} (dispersion ratio = {overdispersion['dispersion_ratio']:.2f}). {'Consider negative binomial regression.' if overdispersion['overdispersion_present'] else 'Poisson model appropriate.'}"
        return interpretations

    def _generate_poisson_recommendations(self, results: Dict) -> List[str]:
        return ["Significant overdispersion detected. Consider negative binomial regression."] if results["overdispersion_test"]["overdispersion_present"] else []

    def negative_binomial_regression(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], covariates: Optional[List[str]] = None, offset: Optional[str] = None) -> Dict[str, Any]:
        """Negative binomial regression for overdispersed count data"""
        results = {"analysis_type": "Negative Binomial Regression", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "model_summary": {}, "incidence_rate_ratios": {}, "confidence_intervals": {}, "goodness_of_fit": {},
                   "dispersion_parameter": {}, "model_comparison": {}, "interpretation": {}, "recommendations": []}
        data = df.copy()
        if isinstance(x_vars, str):
            x_vars = [x_vars]
        if covariates is None:
            covariates = []
        all_vars, formula = x_vars + covariates, f"{y_var} ~ " + " + ".join(all_vars)
        if offset:
            formula += f" + offset({offset})"
        try:
            model = smf.glm(formula, data=data, family=sm.families.NegativeBinomial(alpha=1.0)).fit()
            params, conf_int, pvalues = model.params, model.conf_int(alpha=self.alpha), model.pvalues
            irr, irr_ci_lower, irr_ci_upper = np.exp(params), np.exp(conf_int[0]), np.exp(conf_int[1])
            for var in all_vars:
                results["model_summary"][var] = {"coefficient": float(params[var]), "standard_error": float(model.bse[var]),
                    "z_statistic": float(model.tvalues[var]), "p_value": float(pvalues[var])}
                results["incidence_rate_ratios"][var] = {"irr": float(irr[var]), "ci_lower": float(irr_ci_lower[var]),
                    "ci_upper": float(irr_ci_upper[var]), "significant": pvalues[var] < self.alpha}
            results["dispersion_parameter"] = {"alpha": float(model.family.alpha), "interpretation": "Larger alpha indicates greater overdispersion"}
            results["goodness_of_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic), "deviance": float(model.deviance)}
            results["interpretation"] = self._interpret_negative_binomial(results["incidence_rate_ratios"], all_vars, results["dispersion_parameter"])
            results["recommendations"] = self._generate_negative_binomial_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_negative_binomial(self, irrs: Dict, variables: List[str], dispersion: Dict) -> Dict[str, str]:
        interpretations = {"overall_interpretation": "Negative binomial regression for overdispersed count data.", "variable_interpretations": {}, "dispersion_interpretation": "", "clinical_significance": "IRR > 1 higher expected count, IRR < 1 lower expected count."}
        for var in variables:
            irr_val, is_sig = irrs[var]["irr"], irrs[var]["significant"]
            direction = "increases" if irr_val > 1 else "decreases" if irr_val < 1 else "has no effect on"
            sig_text = "statistically significant" if is_sig else "not statistically significant"
            interpretations["variable_interpretations"][var] = f"{var} {direction} expected count by {irr_val:.3f} times (IRR={irr_val:.3f}, 95% CI: {irrs[var]['ci_lower']:.3f}-{irrs[var]['ci_upper']:.3f}). Effect is {sig_text}."
        interpretations["dispersion_interpretation"] = f"Dispersion parameter alpha = {dispersion['alpha']:.4f}. Models overdispersion in count data."
        return interpretations

    def _generate_negative_binomial_recommendations(self, results: Dict) -> List[str]:
        return ["Negative binomial model successfully fitted. This model is appropriate for overdispersed count data."]

    def generalized_linear_model(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], covariates: Optional[List[str]] = None,
                                    family: str = "gaussian", link: Optional[str] = None, offset: Optional[str] = None) -> Dict[str, Any]:
        """GLM with various distribution families and link functions"""
        results = {"analysis_type": f"Generalized Linear Model ({family})", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "model_summary": {}, "coefficients": {}, "confidence_intervals": {}, "goodness_of_fit": {},
                   "diagnostics": {}, "interpretation": {}, "recommendations": []}
        data = df.copy()
        if isinstance(x_vars, str):
            x_vars = [x_vars]
        if covariates is None:
            covariates = []
        all_vars, formula = x_vars + covariates, f"{y_var} ~ " + " + ".join(all_vars)
        if offset:
            formula += f" + offset({offset})"
        family_map = {"gaussian": sm.families.Gaussian(), "binomial": sm.families.Binomial(), "poisson": sm.families.Poisson(),
                      "gamma": sm.families.Gamma(), "inverse_gaussian": sm.families.InverseGaussian(), "negative_binomial": sm.families.NegativeBinomial()}
        if family not in family_map:
            family_map["gaussian"] = sm.families.Gaussian()
        family_obj = family_map[family]
        if link is not None:
            if hasattr(family_obj, 'links') and link in family_obj.links:
                family_obj.link = family_obj.links[link]()
        try:
            model = smf.glm(formula, data=data, family=family_obj).fit()
            params, conf_int, pvalues = model.params, model.conf_int(alpha=self.alpha), model.pvalues
            for var in all_vars:
                results["model_summary"][var] = {"coefficient": float(params[var]), "standard_error": float(model.bse[var]),
                    "z_statistic": float(model.tvalues[var]), "p_value": float(pvalues[var])}
                results["coefficients"][var] = {"value": float(params[var]), "significant": pvalues[var] < self.alpha}
                results["confidence_intervals"][var] = {"lower": float(conf_int[0][var]), "upper": float(conf_int[1][var])}
            results["goodness_of_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic),
                "deviance": float(model.deviance), "pearson_chi2": float(model.pearson_chi2), "df_resid": int(model.df_resid),
                "family": family, "link": str(family_obj.link)}
            results["diagnostics"] = {"residual_df": int(model.df_resid), "n_observations": int(len(data))}
            results["interpretation"] = self._interpret_glm(results["coefficients"], all_vars, family)
            results["recommendations"] = self._generate_glm_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_glm(self, coeffs: Dict, variables: List[str], family: str) -> Dict[str, str]:
        interpretations = {"overall_interpretation": f"GLM with {family} family and appropriate link function.", "variable_interpretations": {}, "clinical_significance": "Interpret coefficients according to link function."}
        for var in variables:
            coeff_val, is_sig = coeffs[var]["value"], coeffs[var]["significant"]
            sig_text = "statistically significant" if is_sig else "not statistically significant"
            interpretations["variable_interpretations"][var] = f"{var} coefficient = {coeff_val:.4f}. Effect is {sig_text}."
        return interpretations

    def _generate_glm_recommendations(self, results: Dict) -> List[str]:
        return ["GLM successfully fitted. Check residual plots for model diagnostics."]

    def linear_mixed_effects(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], random_effect: str,
                             group_var: str, covariates: Optional[List[str]] = None) -> Dict[str, Any]:
        """LME (Linear Mixed Effects) model for hierarchical data"""
        results = {"analysis_type": "Linear Mixed Effects Model", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "fixed_effects": {}, "random_effects": {}, "model_fit": {}, "variance_components": {},
                   "interpretation": {}, "recommendations": []}
        data = df.copy()
        if isinstance(x_vars, str):
            x_vars = [x_vars]
        if covariates is None:
            covariates = []
        all_vars = x_vars + covariates
        formula = f"{y_var} ~ " + " + ".join(all_vars)
        try:
            model = smf.mixedlm(formula, data, groups=data[group_var], re_formula=f"1 + {random_effect}").fit()
            for var in all_vars:
                results["fixed_effects"][var] = {"coefficient": float(model.fe_params[var]),
                    "standard_error": float(model.bse_fe[var]), "z_statistic": float(model.tvalues[var]),
                    "p_value": float(model.pvalues[var]), "significant": model.pvalues[var] < self.alpha}
            results["random_effects"][random_effect] = {"variance": float(model.cov_re[0, 0]) if hasattr(model, 'cov_re') else 0}
            results["variance_components"] = {"residual_variance": float(model.scale), "group_variance": float(model.cov_re[0, 0]) if hasattr(model, 'cov_re') else 0}
            results["model_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic),
                "n_groups": int(model.n_groups), "n_observations": int(len(data))}
            results["interpretation"] = self._interpret_lme(results["fixed_effects"], all_vars, random_effect)
            results["recommendations"] = self._generate_lme_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_lme(self, fixed_effects: Dict, variables: List[str], random_effect: str) -> Dict[str, str]:
        interpretations = {"overall_interpretation": "Linear mixed effects model for hierarchical/repeated measures data.", "fixed_effects_interpretations": {}, "random_effects_interpretation": f"Random intercept and slope for {random_effect} account for within-group correlation."}
        for var in variables:
            coeff_val, is_sig = fixed_effects[var]["coefficient"], fixed_effects[var]["significant"]
            sig_text = "statistically significant" if is_sig else "not statistically significant"
            interpretations["fixed_effects_interpretations"][var] = f"{var} fixed effect = {coeff_val:.4f}. Effect is {sig_text}."
        return interpretations

    def _generate_lme_recommendations(self, results: Dict) -> List[str]:
        return ["LME model successfully fitted. Random effects capture between-group variability."]

    def generalized_linear_mixed_effects(self, df: pd.DataFrame, y_var: str, x_vars: Union[str, List[str]], random_effect: str,
                                         group_var: str, family: str = "binomial", covariates: Optional[List[str]] = None) -> Dict[str, Any]:
        """GLMM (Generalized Linear Mixed Effects) model"""
        results = {"analysis_type": f"Generalized Linear Mixed Effects Model ({family})", "timestamp": datetime.now().isoformat(),
                   "alpha": self.alpha, "fixed_effects": {}, "random_effects": {}, "model_fit": {},
                   "variance_components": {}, "interpretation": {}, "recommendations": []}
        data = df.copy()
        if isinstance(x_vars, str):
            x_vars = [x_vars]
        if covariates is None:
            covariates = []
        all_vars, formula = x_vars + covariates, f"{y_var} ~ " + " + ".join(all_vars)
        try:
            if family == "binomial":
                model = smf.mixedlm(formula, data, groups=data[group_var], re_formula=f"1 + {random_effect}").fit()
            else:
                results["recommendations"].append("GLMM with non-binomial families requires specialized packages. Using LME approximation.")
                model = smf.mixedlm(formula, data, groups=data[group_var], re_formula=f"1 + {random_effect}").fit()
            for var in all_vars:
                results["fixed_effects"][var] = {"coefficient": float(model.fe_params[var]),
                    "standard_error": float(model.bse_fe[var]), "z_statistic": float(model.tvalues[var]),
                    "p_value": float(model.pvalues[var]), "significant": model.pvalues[var] < self.alpha}
            results["random_effects"][random_effect] = {"variance": float(model.cov_re[0, 0]) if hasattr(model, 'cov_re') else 0}
            results["model_fit"] = {"log_likelihood": float(model.llf), "aic": float(model.aic), "bic": float(model.bic),
                "n_groups": int(model.n_groups), "family": family}
            results["interpretation"] = self._interpret_glmm(results["fixed_effects"], all_vars, random_effect, family)
            results["recommendations"].append("GLMM fitted. For complex GLMMs, consider specialized packages.")
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_glmm(self, fixed_effects: Dict, variables: List[str], random_effect: str, family: str) -> Dict[str, str]:
        interpretations = {"overall_interpretation": f"GLMM with {family} family for correlated/hierarchical data.", "fixed_effects_interpretations": {}, "random_effects_interpretation": f"Random effects for {random_effect} capture extra-binomial variance."}
        for var in variables:
            coeff_val, is_sig = fixed_effects[var]["coefficient"], fixed_effects[var]["significant"]
            sig_text = "statistically significant" if is_sig else "not statistically significant"
            interpretations["fixed_effects_interpretations"][var] = f"{var} fixed effect = {coeff_val:.4f}. Effect is {sig_text}."
        return interpretations

    def meta_analysis_fixed_effects(self, effect_sizes: List[float], standard_errors: List[float],
                                     study_labels: Optional[List[str]] = None) -> Dict[str, Any]:
        """Fixed-effects meta-analysis"""
        results = {"analysis_type": "Fixed-Effects Meta-Analysis", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "individual_studies": {}, "pooled_estimate": {}, "heterogeneity": {}, "forest_plot_data": {},
                   "interpretation": {}, "recommendations": []}
        n_studies = len(effect_sizes)
        if study_labels is None:
            study_labels = [f"Study {i+1}" for i in range(n_studies)]
        try:
            weights = [1 / (se ** 2) for se in standard_errors]
            total_weight = sum(weights)
            pooled_effect = sum(w * es for w, es in zip(weights, effect_sizes)) / total_weight
            se_pooled = np.sqrt(1 / total_weight)
            z_critical = stats.norm.ppf(1 - self.alpha/2)
            ci_lower, ci_upper = pooled_effect - z_critical * se_pooled, pooled_effect + z_critical * se_pooled
            z_statistic, p_value = pooled_effect / se_pooled if se_pooled > 0 else 0, 2 * (1 - stats.norm.cdf(abs(pooled_effect / se_pooled))) if se_pooled > 0 else 1
            q_statistic = sum((w * (es - pooled_effect) ** 2) for w, es in zip(weights, effect_sizes))
            df_q, p_heterogeneity = n_studies - 1, 1 - stats.chi2.cdf(q_statistic, df_q)
            i_squared = max(0, ((q_statistic - df_q) / q_statistic) * 100) if q_statistic > df_q else 0
            results["individual_studies"] = [{"study": label, "effect_size": float(es), "standard_error": float(se),
                "weight": float(w/total_weight*100), "ci_lower": float(es - z_critical*se), "ci_upper": float(es + z_critical*se)}
                for label, es, se, w in zip(study_labels, effect_sizes, standard_errors, weights)]
            results["pooled_estimate"] = {"effect_size": float(pooled_effect), "standard_error": float(se_pooled),
                "ci_lower": float(ci_lower), "ci_upper": float(ci_upper), "z_statistic": float(z_statistic), "p_value": float(p_value), "significant": p_value < self.alpha}
            results["heterogeneity"] = {"q_statistic": float(q_statistic), "df": int(df_q), "p_value": float(p_heterogeneity),
                "i_squared": float(i_squared), "heterogeneity_present": p_heterogeneity < self.alpha}
            results["interpretation"] = self._interpret_fixed_effects_meta(results["pooled_estimate"], results["heterogeneity"])
            results["recommendations"] = self._generate_fixed_effects_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_fixed_effects_meta(self, pooled: Dict, heterogeneity: Dict) -> Dict[str, str]:
        interpretations = {"statistical_interpretation": "", "heterogeneity_interpretation": "", "clinical_significance": ""}
        interpretations["statistical_interpretation"] = f"Pooled effect = {pooled['effect_size']:.4f} (95% CI: {pooled['ci_lower']:.4f} to {pooled['ci_upper']:.4f}), P = {pooled['p_value']:.4f}. {'Significant' if pooled['p_value'] < self.alpha else 'Not significant'} at alpha={self.alpha}."
        interpretations["heterogeneity_interpretation"] = f"Heterogeneity Q = {heterogeneity['q_statistic']:.2f}, df = {heterogeneity['df']}, P = {heterogeneity['p_value']:.4f}. I² = {heterogeneity['i_squared']:.1f}%. {'Low' if heterogeneity['i_squared'] < 25 else 'Moderate' if heterogeneity['i_squared'] < 50 else 'Substantial'} heterogeneity."
        return interpretations

    def _generate_fixed_effects_recommendations(self, results: Dict) -> List[str]:
        recommendations = []
        i_sq = results["heterogeneity"]["i_squared"]
        if i_sq > 50:
            recommendations.append(f"Significant heterogeneity (I²={i_sq:.1f}%). Consider random-effects model.")
        return recommendations

    def meta_analysis_random_effects(self, effect_sizes: List[float], standard_errors: List[float],
                                       study_labels: Optional[List[str]] = None, method: str = "derSimonianLaird") -> Dict[str, Any]:
        """Random-effects meta-analysis with heterogeneity assessment"""
        results = {"analysis_type": "Random-Effects Meta-Analysis", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "individual_studies": {}, "pooled_estimate": {}, "heterogeneity": {}, "prediction_interval": {},
                   "interpretation": {}, "recommendations": []}
        n_studies = len(effect_sizes)
        if study_labels is None:
            study_labels = [f"Study {i+1}" for i in range(n_studies)]
        try:
            weights_fe = [1 / (se ** 2) for se in standard_errors]
            pooled_effect_fe = sum(w * es for w, es in zip(weights_fe, effect_sizes)) / sum(weights_fe)
            q_statistic = sum(w * (es - pooled_effect_fe) ** 2 for w, es in zip(weights_fe, effect_sizes))
            df_q, p_heterogeneity = n_studies - 1, 1 - stats.chi2.cdf(q_statistic, df_q)
            c = max(0, (q_statistic - df_q) / (sum(weights_fe) - sum(w ** 2) / sum(weights_fe))) if q_statistic > df_q else 0
            tau_squared = c
            tau = np.sqrt(tau_squared) if tau_squared > 0 else 0
            i_squared = max(0, ((q_statistic - df_q) / q_statistic) * 100) if q_statistic > df_q else 0
            weights_re = [1 / (se ** 2 + tau_squared) for se in standard_errors]
            total_weight_re = sum(weights_re)
            pooled_effect_re = sum(w * es for w, es in zip(weights_re, effect_sizes)) / total_weight_re
            se_pooled_re = np.sqrt(1 / total_weight_re)
            z_critical = stats.norm.ppf(1 - self.alpha/2)
            ci_lower, ci_upper = pooled_effect_re - z_critical * se_pooled_re, pooled_effect_re + z_critical * se_pooled_re
            z_statistic, p_value = pooled_effect_re / se_pooled_re if se_pooled_re > 0 else 0, 2 * (1 - stats.norm.cdf(abs(pooled_effect_re / se_pooled_re))) if se_pooled_re > 0 else 1
            pred_se = np.sqrt(tau_squared + 1 / total_weight_re)
            pred_ci_low, pred_ci_high = pooled_effect_re - z_critical * pred_se, pooled_effect_re + z_critical * pred_se
            results["individual_studies"] = [{"study": label, "effect_size": float(es), "standard_error": float(se),
                "weight_re": float(w/total_weight_re*100)} for label, es, se, w in zip(study_labels, effect_sizes, standard_errors, weights_re)]
            results["pooled_estimate"] = {"effect_size": float(pooled_effect_re), "standard_error": float(se_pooled_re),
                "ci_lower": float(ci_lower), "ci_upper": float(ci_upper), "z_statistic": float(z_statistic), "p_value": float(p_value), "significant": p_value < self.alpha}
            results["heterogeneity"] = {"q_statistic": float(q_statistic), "df": int(df_q), "p_value": float(p_heterogeneity),
                "i_squared": float(i_squared), "tau_squared": float(tau_squared), "tau": float(tau), "heterogeneity_present": p_heterogeneity < self.alpha}
            results["prediction_interval"] = {"ci_lower": float(pred_ci_low), "ci_upper": float(pred_ci_high)}
            results["interpretation"] = self._interpret_random_effects_meta(results["pooled_estimate"], results["heterogeneity"], results["prediction_interval"])
            results["recommendations"] = self._generate_random_effects_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_random_effects_meta(self, pooled: Dict, heterogeneity: Dict, pred_interval: Dict) -> Dict[str, str]:
        interpretations = {"statistical_interpretation": "", "heterogeneity_interpretation": "", "prediction_interval_interpretation": "", "clinical_significance": ""}
        interpretations["statistical_interpretation"] = f"Random-effects pooled effect = {pooled['effect_size']:.4f} (95% CI: {pooled['ci_lower']:.4f} to {pooled['ci_upper']:.4f}), P = {pooled['p_value']:.4f}. {'Significant' if pooled['p_value'] < self.alpha else 'Not significant'}."
        i_sq, tau = heterogeneity['i_squared'], heterogeneity['tau']
        interpretations["heterogeneity_interpretation"] = f"Heterogeneity: I²={i_sq:.1f}%, τ={tau:.4f} (τ²={heterogeneity['tau_squared']:.4f}). {'Low' if i_sq < 25 else 'Moderate' if i_sq < 50 else 'Substantial'} heterogeneity."
        interpretations["prediction_interval_interpretation"] = f"Prediction interval: {pred_interval['ci_lower']:.4f} to {pred_interval['ci_upper']:.4f}. Estimates where future study effects would fall with 95% confidence."
        return interpretations

    def _generate_random_effects_recommendations(self, results: Dict) -> List[str]:
        recommendations = []
        i_sq = results["heterogeneity"]["i_squared"]
        if i_sq > 75:
            recommendations.append(f"Very high heterogeneity (I²={i_sq:.1f}%). Consider subgroup analysis, meta-regression, or sensitivity analysis.")
        elif i_sq > 50:
            recommendations.append(f"Substantial heterogeneity (I²={i_sq:.1f}%). Explore sources via subgroup analysis.")
        return recommendations

    def non_inferiority_test(self, treatment_mean: float, control_mean: float, treatment_std: float, control_std: float,
                             n_treatment: int, n_control: int, delta_margin: float, test_type: str = "mean") -> Dict[str, Any]:
        """Non-inferiority testing with delta margin"""
        results = {"analysis_type": "Non-Inferiority Test", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "delta_margin": delta_margin, "test_type": test_type, "group_statistics": {}, "test_results": {},
                   "confidence_interval": {}, "interpretation": {}, "recommendations": []}
        try:
            diff = treatment_mean - control_mean
            if test_type == "proportion":
                p_treatment, p_control = treatment_mean, control_mean
                se = np.sqrt((p_treatment * (1 - p_treatment) / n_treatment) + (p_control * (1 - p_control) / n_control))
                results["group_statistics"] = {"treatment_proportion": float(p_treatment), "control_proportion": float(p_control),
                    "risk_difference": float(diff), "risk_ratio": float(p_treatment / p_control) if p_control > 0 else None}
            else:
                se = np.sqrt((treatment_std ** 2 / n_treatment) + (control_std ** 2 / n_control))
                results["group_statistics"] = {"treatment_mean": float(treatment_mean), "control_mean": float(control_mean), "difference": float(diff)}
            z_critical = stats.norm.ppf(1 - self.alpha)
            ci_lower = diff - z_critical * se
            z_statistic = (diff + delta_margin) / se if se > 0 else 0
            p_value = 1 - stats.norm.cdf(z_statistic)
            results["test_results"] = {"difference": float(diff), "standard_error": float(se),
                "z_statistic": float(z_statistic), "p_value_one_sided": float(p_value), "non_inferior": p_value < self.alpha}
            results["confidence_interval"] = {"ci_lower": float(ci_lower), "margin": float(delta_margin)}
            results["interpretation"] = self._interpret_non_inferiority(diff, delta_margin, ci_lower, p_value)
            results["recommendations"] = self._generate_non_inferiority_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_non_inferiority(self, diff: float, delta: float, ci_lower: float, p_value: float) -> Dict[str, str]:
        interpretations = {"statistical_interpretation": "", "clinical_interpretation": "", "conclusion": ""}
        non_inferior = p_value < self.alpha or ci_lower > -delta
        interpretations["statistical_interpretation"] = f"Difference = {diff:.4f}. One-sided 95% CI lower bound = {ci_lower:.4f}. Margin = {delta:.4f}. P = {p_value:.4f}."
        interpretations["clinical_interpretation"] = f"{'Non-inferiority established' if non_inferior else 'Non-inferiority not established'}. Treatment is {'not worse' if non_inferior else 'potentially worse'} than control by > {delta}."
        interpretations["conclusion"] = f"{'Treatment' if non_inferior else 'Insufficient evidence to claim treatment'} is non-inferior to control (margin={delta}). P={p_value:.4f} {'< 0.05' if p_value < self.alpha else '≥ 0.05'}."
        return interpretations

    def _generate_non_inferiority_recommendations(self, results: Dict) -> List[str]:
        return [f"Non-inferiority established (difference={results['test_results']['difference']:.4f})." if results["test_results"]["non_inferior"] else f"Non-inferiority not established. May be worse by > {results['delta_margin']}."]

    def superiority_test(self, treatment_mean: float, control_mean: float, treatment_std: float, control_std: float,
                         n_treatment: int, n_control: int, clinical_relevance: Optional[float] = None, test_type: str = "mean") -> Dict[str, Any]:
        """Superiority testing with clinical relevance"""
        results = {"analysis_type": "Superiority Test", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "clinical_relevance": clinical_relevance, "test_type": test_type, "group_statistics": {}, "test_results": {},
                   "confidence_interval": {}, "clinical_significance": {}, "interpretation": {}, "recommendations": []}
        try:
            diff = treatment_mean - control_mean
            if test_type == "proportion":
                p_treatment, p_control = treatment_mean, control_mean
                se = np.sqrt((p_treatment * (1 - p_treatment) / n_treatment) + (p_control * (1 - p_control) / n_control))
                results["group_statistics"] = {"treatment_proportion": float(p_treatment), "control_proportion": float(p_control),
                    "risk_difference": float(diff), "risk_ratio": float(p_treatment / p_control) if p_control > 0 else None}
            else:
                se = np.sqrt((treatment_std ** 2 / n_treatment) + (control_std ** 2 / n_control))
                results["group_statistics"] = {"treatment_mean": float(treatment_mean), "control_mean": float(control_mean), "difference": float(diff)}
            z_critical = stats.norm.ppf(1 - self.alpha/2)
            ci_lower, ci_upper = diff - z_critical * se, diff + z_critical * se
            z_statistic = diff / se if se > 0 else 0
            p_value_two_sided = 2 * (1 - stats.norm.cdf(abs(z_statistic)))
            results["test_results"] = {"difference": float(diff), "standard_error": float(se),
                "z_statistic": float(z_statistic), "p_value_two_sided": float(p_value_two_sided), "statistically_significant": p_value_two_sided < self.alpha}
            results["confidence_interval"] = {"ci_lower": float(ci_lower), "ci_upper": float(ci_upper)}
            if clinical_relevance is not None:
                results["clinical_significance"] = {"min_clinically_important": float(clinical_relevance),
                    "clinically_significant": ci_lower > clinical_relevance, "both_significant": ci_lower > clinical_relevance and p_value_two_sided < self.alpha}
            results["interpretation"] = self._interpret_superiority(diff, ci_lower, ci_upper, p_value_two_sided, clinical_relevance)
            results["recommendations"] = self._generate_superiority_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_superiority(self, diff: float, ci_lower: float, ci_upper: float, p_value: float, clinical_relevance: Optional[float]) -> Dict[str, str]:
        interpretations = {"statistical_interpretation": "", "clinical_interpretation": "", "overall_conclusion": ""}
        stat_sig = p_value < self.alpha
        interpretations["statistical_interpretation"] = f"Difference = {diff:.4f} (95% CI: {ci_lower:.4f} to {ci_upper:.4f}). P = {p_value:.4f}. {'Statistically significant' if stat_sig else 'Not statistically significant'}."
        if clinical_relevance is not None:
            clin_sig = ci_lower > clinical_relevance
            interpretations["clinical_interpretation"] = f"MCID = {clinical_relevance:.4f}. {'Clinically significant' if clin_sig else 'Not clinically significant'} (lower CI {' > ' if ci_lower > clinical_relevance else '≤'} {clinical_relevance})."
            both_sig = stat_sig and clin_sig
            interpretations["overall_conclusion"] = f"{'Treatment demonstrates both' if both_sig else "Treatment doesn't demonstrate both"} statistical and clinical significance. {'Statistical' if stat_sig else 'No statistical'} significance, {'clinical' if clin_sig else 'no clinical'} significance."
        else:
            interpretations["clinical_interpretation"] = "No clinical relevance threshold specified."
            interpretations["overall_conclusion"] = f"Treatment is {'statistically superior' if stat_sig else 'not statistically superior'} to control (p={p_value:.4f})."
        return interpretations

    def _generate_superiority_recommendations(self, results: Dict) -> List[str]:
        recommendations = []
        stat_sig = results["test_results"]["statistically_significant"]
        if stat_sig:
            if results.get("clinical_significance") is not None:
                clin_sig = results["clinical_significance"]["clinically_significant"]
                recommendations.append(f"Treatment shows {'both statistical and clinical' if clin_sig else 'statistical but not clinical'} superiority.")
            else:
                recommendations.append(f"Statistically significant difference found. Assess clinical relevance.")
        else:
            recommendations.append("No statistically significant difference detected. Consider larger sample size.")
        return recommendations

    def equivalence_test(self, treatment_mean: float, control_mean: float, treatment_std: float, control_std: float,
                         n_treatment: int, n_control: int, equivalence_margin: float, test_type: str = "mean") -> Dict[str, Any]:
        """Equivalence testing with confidence interval approach"""
        results = {"analysis_type": "Equivalence Test (TOST)", "timestamp": datetime.now().isoformat(), "alpha": self.alpha,
                   "equivalence_margin": equivalence_margin, "test_type": test_type, "group_statistics": {},
                   "confidence_interval": {}, "tost_results": {}, "interpretation": {}, "recommendations": []}
        try:
            if test_type == "ratio":
                ratio, control_mean_safe = treatment_mean / control_mean if control_mean > 0 else 0, max(control_mean, 0.001)
                log_ratio = np.log(ratio) if ratio > 0 else 0
                se = np.sqrt((treatment_std ** 2 / (n_treatment * max(treatment_mean, 0.001) ** 2)) + (control_std ** 2 / (n_control * control_mean_safe ** 2)))
                log_lower, log_upper = np.log(0.8), np.log(1.25)
                z_critical = stats.norm.ppf(1 - self.alpha)
                ci_low_log, ci_high_log = log_ratio - z_critical * se, log_ratio + z_critical * se
                ci_low, ci_high = np.exp(ci_low_log), np.exp(ci_high_log)
                t1 = (log_ratio - log_lower) / se if se > 0 else 0
                t2 = (log_upper - log_ratio) / se if se > 0 else 0
                p_tost = max(1 - stats.norm.cdf(t1), 1 - stats.norm.cdf(t2))
                results["group_statistics"] = {"treatment_mean": float(treatment_mean), "control_mean": float(control_mean), "ratio": float(ratio)}
                results["confidence_interval"] = {"ratio_ci_lower": float(ci_low), "ratio_ci_upper": float(ci_high), "equivalence_bounds": [0.8, 1.25]}
                results["tost_results"] = {"p_value_tost": float(p_tost), "equivalent": ci_low >= 0.8 and ci_high <= 1.25}
            else:
                diff = treatment_mean - control_mean
                se = np.sqrt((treatment_std ** 2 / n_treatment) + (control_std ** 2 / n_control))
                z_critical = stats.norm.ppf(1 - self.alpha)
                ci_low, ci_high = diff - z_critical * se, diff + z_critical * se
                t1 = (diff - (-equivalence_margin)) / se if se > 0 else 0
                t2 = (equivalence_margin - diff) / se if se > 0 else 0
                p_tost = max(1 - stats.norm.cdf(t1), 1 - stats.norm.cdf(t2))
                results["group_statistics"] = {"treatment_mean": float(treatment_mean), "control_mean": float(control_mean), "difference": float(diff)}
                results["confidence_interval"] = {"ci_lower": float(ci_low), "ci_upper": float(ci_high), "equivalence_bounds": [-equivalence_margin, equivalence_margin]}
                results["tost_results"] = {"p_value_tost": float(p_tost), "equivalent": ci_low >= -equivalence_margin and ci_high <= equivalence_margin}
            results["interpretation"] = self._interpret_equivalence(diff, ci_low, ci_high, equivalence_margin, p_tost)
            results["recommendations"] = self._generate_equivalence_recommendations(results)
        except Exception as e:
            results["error"] = str(e)
            results["recommendations"].append(f"Error: {e}")
        return results

    def _interpret_equivalence(self, diff: float, ci_low: float, ci_high: float, margin: float, p_tost: float) -> Dict[str, str]:
        interpretations = {"statistical_interpretation": "", "clinical_interpretation": "", "conclusion": ""}
        equivalent = p_tost < self.alpha and ci_low >= -margin and ci_high <= margin
        interpretations["statistical_interpretation"] = f"Difference = {diff:.4f} (90% CI: {ci_low:.4f} to {ci_high:.4f}). Margin = ±{margin:.4f}. TOST P = {p_tost:.4f}."
        interpretations["clinical_interpretation"] = f"{'Equivalence established' if equivalent else 'Equivalence not established'}. Treatments are {'considered equivalent' if equivalent else 'not equivalent'} within margin ±{margin}."
        interpretations["conclusion"] = f"{'Treatments are equivalent' if equivalent else 'Treatments are not equivalent'} (margin={margin}, P={p_tost:.4f}). CI {ci_low:.4f} to {ci_high:.4f} {'within' if equivalent else 'outside'} equivalence bounds."
        return interpretations

    def _generate_equivalence_recommendations(self, results: Dict) -> List[str]:
        margin, ci_low, ci_high = results["equivalence_margin"], results["confidence_interval"]["ci_lower"], results["confidence_interval"]["ci_upper"]
        return [f"Equivalence established (CI within ±{margin}). Treatments can be considered interchangeable." if results["tost_results"]["equivalent"] else f"Equivalence not established. CI ({ci_low:.4f} to {ci_high:.4f}) exceeds margin ±{margin}."]

    def export_results(self, results: Dict, filepath: str) -> None:
        """Export results to JSON file"""
        with open(filepath, "w") as f:
            json.dump(results, f, indent=2, default=str)

    def get_analysis_history(self) -> List[Dict]:
        """Return analysis history"""
        return self.analysis_history

if __name__ == "__main__":
    print("Advanced Biostatistics Module initialized.")
    print("All methods comply with GLP, GCP, FDA/EMA, and ICH E9 guidelines.")
