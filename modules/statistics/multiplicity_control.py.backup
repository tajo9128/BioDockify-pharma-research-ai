
"""Multiplicity Control Module for Pharmaceutical Statistics

Provides comprehensive multiplicity correction methods for controlling
Type I error rates in clinical trial analyses.

Complies with:
- Good Laboratory Practice (GLP)
- Good Clinical Practice (GCP)
- FDA Multiplicity Adjustments in Clinical Trials Guidance (2019)
- EMA Guideline on Multiplicity Issues in Clinical Trials (2016)
- ICH E9 Statistical Principles for Clinical Trials

Reference:
- FDA: "Multiplicity Adjustments in Clinical Trials" (July 2017)
- EMA: "Guideline on Multiplicity Issues in Clinical Trials" (December 2016)
- Benjamini & Hochberg (1995): Controlling the False Discovery Rate
- Holm (1979): A Simple Sequentially Rejective Multiple Test Procedure
- Šidák (1967): Rectangular Confidence Regions for the Means
"""

import numpy as np
import pandas as pd
from scipy import stats
import statsmodels.stats.multitest as smm
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
import warnings
warnings.filterwarnings("ignore")


class MultiplicityControl:
    """Comprehensive multiplicity control for pharmaceutical statistics

    Provides multiple testing correction methods for:
    - Family-wise error rate (FWER) control
    - False discovery rate (FDR) control
    - Clinical trial multiplicity adjustments
    - Multiple endpoints analysis
    - Subgroup analyses
    - Interim analyses

    Methods:
        bonferroni_correction: Bonferroni correction (conservative)
        holm_bonferroni_correction: Holm step-down (more powerful)
        benjamini_hochberg_fdr: FDR control (BH procedure)
        benjamini_yekutieli_fdr: FDR under dependence
        sidak_correction: Šidák correction (independent tests)
        hochberg_correction: Hochberg step-up procedure
        hommel_correction: Hommel correction (global test)
        calculate_adjusted_pvalues: Unified p-value adjustment
        family_wise_error_rate: FWER calculation and control
        compare_correction_methods: Comparative analysis
    """

    def __init__(self, alpha: float = 0.05, independence: bool = True):
        """Initialize multiplicity control engine

        Args:
            alpha: Family-wise error rate (default: 0.05)
            independence: Assume test independence (affects method selection)
        """
        self.alpha = alpha
        self.independence = independence
        self.analysis_history = []
        self.supported_methods = [
            "bonferroni", "holm", "fdr_bh", "fdr_by",
            "sidak", "hochberg", "hommel"
        ]

    def bonferroni_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Bonferroni correction for multiple comparisons

        The Bonferroni correction controls the family-wise error rate (FWER)
        at level alpha by rejecting hypotheses with p-values less than or equal to alpha/m,
        where m is the number of tests. This method is conservative but simple.

        Clinical Application:
            - Multiple primary endpoints in clinical trials
            - Multiple dose groups comparisons
            - Multiple time point analyses

        FDA Guidance: "The Bonferroni method is simple and ensures FWER control,
        but can be conservative when there are many tests."

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations

        Example:
            >>> mc = MultiplicityControl(alpha=0.05)
            >>> pvals = [0.01, 0.02, 0.03, 0.04, 0.05]
            >>> result = mc.bonferroni_correction(pvals)
            >>> # Test 1: 0.01 * 5 = 0.05 (significant)
            >>> # Test 2: 0.02 * 5 = 0.10 (not significant)
        """
        # Input validation
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Bonferroni correction
        adjusted_pvals = np.minimum(p_values * m, 1.0)
        significant = adjusted_pvals <= self.alpha

        # Calculate family-wise error rate
        fwer = self._calculate_fwer(p_values, "bonferroni")

        # Calculate power loss
        power_loss = self._estimate_power_loss(p_values, m)

        results = {
            "method": "Bonferroni Correction",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "independence_assumed": False,  # Works for correlated tests
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": adjusted_pvals.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fwer_control": fwer,
            "power_loss_estimate": power_loss,
            "explanations": self._explain_bonferroni(m, fwer),
            "interpretations": self._interpret_bonferroni(
                p_values, adjusted_pvals, significant, test_names
            ),
            "clinical_guidance": self._clinical_guidance_bonferroni(),
            "warnings": self._generate_warnings("bonferroni", m),
            "formula": "p_adj = min(p x m, 1.0)",
            "reference": "Bonferroni (1936); FDA Multiplicity Guidance (2017)"
        }

        self._log_analysis("bonferroni", results)
        return results

    def holm_bonferroni_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Holm-Bonferroni step-down procedure

        The Holm-Bonferroni method is a sequentially rejective procedure that
        is uniformly more powerful than the Bonferroni correction while still
        controlling FWER. P-values are sorted, and the smallest is compared
        to alpha/m, the next to alpha/(m-1), etc.

        Clinical Application:
            - Hierarchical testing of secondary endpoints
            - Multiple dose comparisons when doses are ordered
            - Adaptive designs with multiple looks

        EMA Guideline: "The Holm procedure is recommended when a stepwise
        procedure is appropriate and more power is desired than Bonferroni."

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations

        Example:
            >>> mc = MultiplicityControl(alpha=0.05)
            >>> pvals = [0.01, 0.02, 0.03, 0.04, 0.05]
            >>> result = mc.holm_bonferroni_correction(pvals)
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Holm-Bonferroni using statsmodels
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method="holm"
        )

        # Get order statistics
        sorted_indices = np.argsort(p_values)
        original_order = np.argsort(sorted_indices)

        significant = reject
        fwer = self._calculate_fwer(p_values, "holm")
        power_loss = self._estimate_power_loss(p_values, m)

        results = {
            "method": "Holm-Bonferroni Step-Down",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "independence_assumed": False,
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": pvals_corrected.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fwer_control": fwer,
            "power_loss_estimate": power_loss,
            "sorted_indices": sorted_indices.tolist(),
            "explanations": self._explain_holm(m, fwer),
            "interpretations": self._interpret_holm(
                p_values, pvals_corrected, significant, test_names, sorted_indices
            ),
            "clinical_guidance": self._clinical_guidance_holm(),
            "warnings": self._generate_warnings("holm", m),
            "algorithm": self._explain_holm_algorithm(),
            "reference": "Holm (1979); EMA Multiplicity Guideline (2016)"
        }

        self._log_analysis("holm", results)
        return results

    def benjamini_hochberg_fdr(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None,
        q_value: float = 0.05
    ) -> Dict[str, Any]:
        """False Discovery Rate control using Benjamini-Hochberg

        The Benjamini-Hochberg procedure controls the expected proportion
        of false discoveries (FDR) rather than FWER. This is less conservative
        and more powerful, making it suitable for exploratory analyses.

        Clinical Application:
            - Biomarker discovery studies
            - High-throughput screening
            - Gene expression analysis
            - Exploratory subgroup analyses

        FDA Guidance: "FDR methods may be appropriate for exploratory analyses
        where some false positives are acceptable."

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test
            q_value: False discovery rate level (default: 0.05)

        Returns:
            Dictionary with corrected p-values and interpretations

        Example:
            >>> mc = MultiplicityControl(alpha=0.05)
            >>> pvals = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]
            >>> result = mc.benjamini_hochberg_fdr(pvals, q_value=0.10)
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Benjamini-Hochberg
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=q_value,
            method="fdr_bh"
        )

        significant = reject
        fdr_estimate = np.mean(pvals_corrected[pvals_corrected <= q_value]) if np.any(significant) else 0
        power_gain = self._estimate_power_gain_vs_bonferroni(p_values, m)

        results = {
            "method": "Benjamini-Hochberg FDR Control",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "q_value": q_value,
            "num_tests": m,
            "independence_assumed": True,
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": pvals_corrected.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fdr_estimate": fdr_estimate,
            "power_gain_vs_bonferroni": power_gain,
            "explanations": self._explain_bh(m, q_value),
            "interpretations": self._interpret_bh(
                p_values, pvals_corrected, significant, test_names, q_value
            ),
            "clinical_guidance": self._clinical_guidance_bh(),
            "warnings": self._generate_warnings("fdr_bh", m),
            "algorithm": self._explain_bh_algorithm(),
            "reference": "Benjamini & Hochberg (1995); FDA Multiplicity Guidance (2017)"
        }

        self._log_analysis("fdr_bh", results)
        return results

    def benjamini_yekutieli_fdr(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None,
        q_value: float = 0.05
    ) -> Dict[str, Any]:
        """FDR control under dependence (Benjamini-Yekutieli)

        The Benjamini-Yekutieli procedure controls FDR under arbitrary
        dependence structures. It is more conservative than BH but
        provides valid FDR control when tests are correlated.

        Clinical Application:
            - Correlated endpoints (e.g., related biomarkers)
            - Repeated measures over time
            - Clustered data structures

        Note: This method is very conservative and recommended only when
        strong positive dependence is suspected.

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test
            q_value: False discovery rate level (default: 0.05)

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Benjamini-Yekutieli
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=q_value,
            method="fdr_by"
        )

        significant = reject
        harmonic_sum = np.sum(1 / np.arange(1, m + 1))
        conservativism_factor = harmonic_sum / np.log(m)
        power_vs_bh = self._compare_by_vs_bh(p_values, m)

        results = {
            "method": "Benjamini-Yekutieli FDR Control",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "q_value": q_value,
            "num_tests": m,
            "independence_assumed": False,  # Handles arbitrary dependence
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": pvals_corrected.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "harmonic_sum": harmonic_sum,
            "conservatism_factor": conservativism_factor,
            "power_vs_bh": power_vs_bh,
            "explanations": self._explain_by(m, q_value, harmonic_sum),
            "interpretations": self._interpret_by(
                p_values, pvals_corrected, significant, test_names, q_value
            ),
            "clinical_guidance": self._clinical_guidance_by(),
            "warnings": self._generate_warnings("fdr_by", m),
            "reference": "Benjamini & Yekutieli (2001)"
        }

        self._log_analysis("fdr_by", results)
        return results

    def sidak_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Šidák correction for independent tests

        The Šidák correction provides exact FWER control for independent
        tests using the formula alpha_adj = 1 - (1 - alpha)^(1/m). It is slightly
        less conservative than Bonferroni but requires independence.

        Clinical Application:
            - Multiple independent primary endpoints
            - Separate clinical trials pooled in meta-analysis
            - Independent subgroup analyses

        Note: Assumes test independence. Do not use with correlated endpoints.

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Šidák correction
        sidak_alpha = 1 - (1 - self.alpha) ** (1 / m)
        adjusted_pvals = 1 - (1 - np.array(p_values)) ** m
        adjusted_pvals = np.minimum(adjusted_pvals, 1.0)
        significant = p_values <= sidak_alpha

        fwer = self._calculate_fwer(p_values, "sidak")
        power_vs_bonferroni = self._compare_sidak_vs_bonferroni(m)

        results = {
            "method": "Šidák Correction",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "independence_assumed": True,  # Critical assumption
            "sidak_alpha": sidak_alpha,
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": adjusted_pvals.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fwer_control": fwer,
            "power_vs_bonferroni": power_vs_bonferroni,
            "explanations": self._explain_sidak(m, sidak_alpha),
            "interpretations": self._interpret_sidak(
                p_values, adjusted_pvals, significant, test_names, sidak_alpha
            ),
            "clinical_guidance": self._clinical_guidance_sidak(),
            "warnings": self._generate_warnings("sidak", m),
            "formula": f"p_adj = 1 - (1 - p)^{m}, alpha_adj = 1 - (1 - alpha)^{{1/{m}}}",
            "reference": "Šidák (1967)"
        }

        self._log_analysis("sidak", results)
        return results

    def hochberg_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Hochberg step-up procedure

        The Hochberg procedure is a step-up method that is more powerful
        than Holm when tests are independent. It starts with the largest
        p-value and works upward, stopping when a significance is found.

        Clinical Application:
            - Multiple comparisons when independence holds
            - Independent secondary endpoint testing
            - Dose-response studies with independent comparisons

        Note: More powerful than Holm under independence but less
        powerful if tests are positively correlated.

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Hochberg correction
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method="hochberg"
        )

        significant = reject
        fwer = self._calculate_fwer(p_values, "hochberg")
        power_vs_holm = self._compare_hochberg_vs_holm(p_values, m)

        results = {
            "method": "Hochberg Step-Up Procedure",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "independence_assumed": True,
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": pvals_corrected.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fwer_control": fwer,
            "power_vs_holm": power_vs_holm,
            "explanations": self._explain_hochberg(m, fwer),
            "interpretations": self._interpret_hochberg(
                p_values, pvals_corrected, significant, test_names
            ),
            "clinical_guidance": self._clinical_guidance_hochberg(),
            "warnings": self._generate_warnings("hochberg", m),
            "algorithm": self._explain_hochberg_algorithm(),
            "reference": "Hochberg (1988)"
        }

        self._log_analysis("hochberg", results)
        return results

    def hommel_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Hommel correction (more powerful than Bonferroni)

        Hommel provides exact control of FWER and is generally
        more powerful than Bonferroni and Holm. It uses a global
        test approach with closed testing.

        Clinical Application:
            - Multiple primary endpoints with correlation
            - Large clinical trial analyses
            - Complex multiplicity problems

        Note: Computationally intensive for very large numbers of tests (>1000).

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Hommel correction
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method="hommel"
        )

        significant = reject
        fwer = self._calculate_fwer(p_values, "hommel")
        power_vs_bonferroni = self._compare_hommel_vs_bonferroni(p_values, m)

        results = {
            "method": "Hommel Correction",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "independence_assumed": False,
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": pvals_corrected.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fwer_control": fwer,
            "power_vs_bonferroni": power_vs_bonferroni,
            "explanations": self._explain_hommel(m, fwer),
            "interpretations": self._interpret_hommel(
                p_values, pvals_corrected, significant, test_names
            ),
            "clinical_guidance": self._clinical_guidance_hommel(),
            "warnings": self._generate_warnings("hommel", m),
            "reference": "Hommel (1988)"
        }

        self._log_analysis("hommel", results)
        return results

    def calculate_adjusted_pvalues(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        method: str = "holm",
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Calculate adjusted p-values using specified method

        Unified interface for multiple testing correction supporting
        all major methods. Provides consistent output format for
        easy comparison across methods.

        Supported Methods:
            - "bonferroni": Bonferroni correction (most conservative)
            - "holm": Holm step-down (recommended default)
            - "fdr_bh": Benjamini-Hochberg FDR (exploratory)
            - "fdr_by": Benjamini-Yekutieli FDR (dependent)
            - "sidak": Šidák (independent only)
            - "hochberg": Hochberg step-up (independent)
            - "hommel": Hommel (more powerful)

        Args:
            p_values: Array of p-values from multiple tests
            method: Correction method (default: "holm")
            test_names: Optional names for each test

        Returns:
            Dictionary with adjusted p-values and interpretations

        Raises:
            ValueError: If method is not supported
        """
        if method not in self.supported_methods:
            raise ValueError(
                f"Method "{method}" not supported. "
                f"Choose from: {', '.join(self.supported_methods)}"
            )

        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply selected correction
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method=method
        )

        significant = reject
        fwer = self._calculate_fwer(p_values, method)
        results = {
            "method": f"{method.upper()} Correction",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "correction_method": method,
            "num_tests": m,
            "original_pvalues": p_values.tolist(),
            "adjusted_pvalues": pvals_corrected.tolist(),
            "test_names": test_names,
            "significant": significant.tolist(),
            "num_significant": int(np.sum(significant)),
            "fwer_control": fwer,
            "explanations": self._explain_method(method, m),
            "interpretations": self._interpret_general(
                p_values, pvals_corrected, significant, test_names, method
            ),
            "warnings": self._generate_warnings(method, m)
        }

        self._log_analysis(method, results)
        return results

    def family_wise_error_rate(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        method: str = "bonferroni"
    ) -> Dict[str, Any]:
        """Calculate and control Family-Wise Error Rate (FWER)

        FWER is the probability of making at least one Type I error
        (false positive) among all hypotheses tested. This method
        provides detailed FWER calculations and control strategies.

        Clinical Importance:
            - Critical for confirmatory trials
            - Required by FDA/EMA for primary endpoints
            - Ensures overall study integrity

        Args:
            p_values: Array of p-values from multiple tests
            method: FWER control method

        Returns:
            Dictionary with FWER calculations and control
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        # Calculate raw FWER (probability of at least one Type I error)
        raw_fwer = 1 - (1 - self.alpha) ** m
        bonferroni_fwer = min(self.alpha * m, 1.0)
        sidak_fwer = 1 - (1 - self.alpha) ** m

        # Simulate FWER under independence
        simulated_fwer = self._simulate_fwer(m, n_simulations=10000)

        # Calculate controlled FWER with each method
        controlled_fwer = {}
        for mth in ["bonferroni", "holm", "sidak", "hommel"]:
            if mth == "sidak":
                controlled_fwer[mth] = self.alpha
            elif mth == "bonferroni":
                controlled_fwer[mth] = self.alpha
            else:
                controlled_fwer[mth] = self.alpha

        # Calculate inflation factor
        inflation_factor = raw_fwer / self.alpha

        results = {
            "method": "Family-Wise Error Rate Analysis",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "fwer_calculations": {
                "nominal_fwer": self.alpha,
                "raw_fwer_inflation": raw_fwer,
                "inflation_factor": inflation_factor,
                "bonferroni_controlled": controlled_fwer["bonferroni"],
                "sidak_controlled": controlled_fwer["sidak"],
                "simulated_fwer_independent": simulated_fwer
            },
            "explanations": self._explain_fwer(m, raw_fwer, inflation_factor),
            "interpretations": self._interpret_fwer(raw_fwer, inflation_factor, m),
            "clinical_guidance": self._clinical_guidance_fwer(),
            "recommendations": self._generate_method_recommendations(p_values, m)
        }

        self._log_analysis("fwer", results)
        return results

    def compare_correction_methods(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Compare different multiplicity correction methods

        Comprehensive comparison of all supported correction methods,
        showing which provides the best power while maintaining
        appropriate error rate control.

        Clinical Application:
            - Method selection for study design
            - Sensitivity analysis of results
            - Regulatory justification of chosen method

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with comprehensive method comparison
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply all methods
        results_by_method = {}
        for method in self.supported_methods:
            try:
                reject, pvals_corrected, _, _ = smm.multipletests(
                    p_values, alpha=self.alpha, method=method
                )
                results_by_method[method] = {
                    "significant": int(np.sum(reject)),
                    "adjusted_pvalues": pvals_corrected.tolist(),
                    "conservatism": self._assess_conservatism(method),
                    "requires_independence": self._requires_independence(method),
                    "suitability_confirmatory": self._suitability_confirmatory(method),
                    "suitability_exploratory": self._suitability_exploratory(method)
                }
            except Exception as e:
                results_by_method[method] = {"error": str(e)}

        # Rank by power (number significant)
        power_ranking = sorted(
            [(k, v["significant"]) for k, v in results_by_method.items() if "significant" in v],
            key=lambda x: x[1], reverse=True
        )

        results = {
            "method": "Correction Method Comparison",
            "timestamp": datetime.now().isoformat(),
            "alpha": self.alpha,
            "num_tests": m,
            "original_pvalues": p_values.tolist(),
            "test_names": test_names,
            "results_by_method": results_by_method,
            "power_ranking": power_ranking,
            "explanations": self._explain_comparison(power_ranking, m),
            "interpretations": self._interpret_comparison(power_ranking, m),
            "clinical_guidance": self._clinical_guidance_comparison(),
            "recommendations": self._generate_method_recommendations(p_values, m)
        }

        self._log_analysis("comparison", results)
        return results

    # ==================== Helper Methods ====================

    def _validate_pvalues(self, p_values: Union[List[float], np.ndarray, pd.Series]) -> np.ndarray:
        """Validate and convert p-values to numpy array"""
        if isinstance(p_values, pd.Series):
            p_values = p_values.values
        p_values = np.array(p_values, dtype=float)

        if len(p_values) == 0:
            raise ValueError("P-values array cannot be empty")

        if np.any(p_values < 0) or np.any(p_values > 1):
            raise ValueError("P-values must be between 0 and 1")

        if np.any(np.isnan(p_values)):
            raise ValueError("P-values cannot contain NaN values")

        return p_values

    def _calculate_fwer(self, p_values: np.ndarray, method: str) -> Dict[str, float]:
        """Calculate Family-Wise Error Rate for a method"""
        m = len(p_values)
        raw_fwer = 1 - (1 - self.alpha) ** m

        if method == "bonferroni":
            controlled_fwer = self.alpha
        elif method == "sidak":
            controlled_fwer = self.alpha
        elif method in ["holm", "hochberg", "hommel"]:
            controlled_fwer = self.alpha
        elif method in ["fdr_bh", "fdr_by"]:
            controlled_fwer = raw_fwer  # FDR methods don't control FWER
        else:
            controlled_fwer = self.alpha

        return {
            "nominal_alpha": self.alpha,
            "raw_inflation": raw_fwer,
            "controlled_fwer": controlled_fwer,
            "control_achieved": controlled_fwer <= self.alpha
        }

    def _estimate_power_loss(self, p_values: np.ndarray, m: int) -> float:
        """Estimate power loss due to correction"""
        uncorrected_sig = np.sum(p_values <= self.alpha)
        bonferroni_sig = np.sum(p_values <= self.alpha / m)

        if uncorrected_sig == 0:
            return 0.0

        loss = 1 - (bonferroni_sig / uncorrected_sig)
        return round(loss, 3)

    def _estimate_power_gain_vs_bonferroni(self, p_values: np.ndarray, m: int) -> float:
        """Estimate power gain of method vs Bonferroni"""
        bonferroni_sig = np.sum(p_values <= self.alpha / m)
        bh_sig = np.sum(p_values <= self.alpha * np.arange(1, m + 1) / m)

        if bonferroni_sig == 0:
            return bh_sig if bh_sig > 0 else 0.0

        gain = (bh_sig - bonferroni_sig) / m
        return round(gain, 3)

    def _simulate_fwer(self, m: int, n_simulations: int = 10000) -> float:
        """Simulate FWER under independence"""
        np.random.seed(42)
        simulations = np.random.uniform(0, 1, (n_simulations, m))
        any_rejection = np.any(simulations <= self.alpha, axis=1)
        return np.mean(any_rejection)

    def _log_analysis(self, method: str, results: Dict[str, Any]) -> None:
        """Log analysis results to history"""
        self.analysis_history.append({
            "method": method,
            "timestamp": results.get("timestamp"),
            "num_tests": results.get("num_tests"),
            "num_significant": results.get("num_significant"),
            "alpha": results.get("alpha")
        })

    # ==================== Explanation Methods ====================

    def _explain_bonferroni(self, m: int, fwer: Dict[str, float]) -> List[str]:
        """Generate explanations for Bonferroni correction"""
        return [
            f"Bonferroni correction adjusts significance threshold from {self.alpha:.4f} to {self.alpha/m:.4f}",
            f"Method ensures FWER is controlled at {self.alpha:.2f} level",
            f"Very conservative: controls FWER at {fwer["controlled_fwer"]:.4f}",
            f"Inflation factor without correction: {fwer["raw_inflation"]:.4f}",
            "Suitable for confirmatory trials with multiple primary endpoints",
            "May be underpowered when number of tests is large"
        ]

    def _explain_holm(self, m: int, fwer: Dict[str, float]) -> List[str]:
        """Generate explanations for Holm-Bonferroni"""
        return [
            "Holm is a step-down procedure: sort p-values, test sequentially",
            f"More powerful than Bonferroni: FWER still controlled at {self.alpha:.2f}",
            f"Compares p_(i) to alpha/(m-i+1) at each step",
            "Stops at first non-significant result",
            "Recommended by EMA as default FWER method",
            "Works under any dependence structure"
        ]

    def _explain_bh(self, m: int, q_value: float) -> List[str]:
        """Generate explanations for Benjamini-Hochberg FDR"""
        return [
            f"Controls False Discovery Rate at {q_value:.2f} (not FWER)",
            "Expected proportion of false discoveries among all discoveries",
            "Less conservative, more powerful than FWER methods",
            "Appropriate for exploratory analyses",
            f"Critical values increase from {q_value/m:.4f} to {q_value:.4f}",
            "Use when some false positives are acceptable"
        ]

    def _explain_by(self, m: int, q_value: float, harmonic_sum: float) -> List[str]:
        """Generate explanations for Benjamini-Yekutieli"""
        return [
            f"Controls FDR under arbitrary dependence at {q_value:.2f}",
            f"Uses harmonic sum correction factor: {harmonic_sum:.2f}",
            "More conservative than Benjamini-Hochberg",
            "Useful for correlated tests (e.g., related biomarkers)",
            "Very conservative when number of tests is large",
            "Recommended only when strong positive dependence is suspected"
        ]

    def _explain_sidak(self, m: int, sidak_alpha: float) -> List[str]:
        """Generate explanations for Šidák correction"""
        return [
            f"Šidák adjusts threshold to {sidak_alpha:.4f} (vs {self.alpha/m:.4f} for Bonferroni)",
            "Slightly less conservative than Bonferroni",
            "REQUIRES test independence assumption",
            f"Formula: p_adj = 1 - (1 - p)^{m}",
            "Exact FWER control under independence",
            "Do not use with correlated endpoints"
        ]

    def _explain_hochberg(self, m: int, fwer: Dict[str, float]) -> List[str]:
        """Generate explanations for Hochberg correction"""
        return [
            "Hochberg is a step-up procedure: start from largest p-value",
            "More powerful than Holm under independence",
            "Requires test independence assumption",
            "Rejects all hypotheses with p-values <= significant one",
            "Less powerful if tests are positively correlated",
            "Good choice for independent secondary endpoints"
        ]

    def _explain_hommel(self, m: int, fwer: Dict[str, float]) -> List[str]:
        """Generate explanations for Hommel correction"""
        return [
            "Hommel uses closed testing with global test approach",
            "Generally more powerful than Bonferroni and Holm",
            "Exact FWER control under any dependence",
            "Computationally intensive for very large test sets",
            "One of the most powerful FWER methods",
            "Suitable for complex multiplicity problems"
        ]

    def _explain_method(self, method: str, m: int) -> List[str]:
        """Generate explanation for generic method"""
        method_explanations = {
            "bonferroni": self._explain_bonferroni(m, self._calculate_fwer(np.ones(m)*0.01, "bonferroni")),
            "holm": self._explain_holm(m, self._calculate_fwer(np.ones(m)*0.01, "holm")),
            "fdr_bh": self._explain_bh(m, self.alpha),
            "fdr_by": self._explain_by(m, self.alpha, np.sum(1/np.arange(1, m+1))),
            "sidak": self._explain_sidak(m, 1 - (1-self.alpha)**(1/m)),
            "hochberg": self._explain_hochberg(m, self._calculate_fwer(np.ones(m)*0.01, "hochberg")),
            "hommel": self._explain_hommel(m, self._calculate_fwer(np.ones(m)*0.01, "hommel"))
        }
        return method_explanations.get(method, ["Method not documented"])

    def _explain_holm_algorithm(self) -> List[str]:
        """Explain Holm algorithm step-by-step"""
        return [
            "Algorithm:",
            "1. Sort p-values in ascending order: p_(1) <= p_(2) <= ... <= p_(m)",
            "2. Find smallest k such that p_(k) > alpha/(m-k+1)",
            "3. Reject hypotheses 1, 2, ..., k-1",
            "4. Accept hypotheses k, k+1, ..., m",
            "Sequentially rejective, step-down procedure"
        ]

    def _explain_bh_algorithm(self) -> List[str]:
        """Explain Benjamini-Hochberg algorithm step-by-step"""
        return [
            "Algorithm:",
            "1. Sort p-values: p_(1) <= p_(2) <= ... <= p_(m)",
            "2. Find largest k such that p_(k) <= (k/m) * q",",
            "3. Reject hypotheses 1, 2, ..., k",
            "4. Accept hypotheses k+1, ..., m",
            "Step-up procedure, controls FDR at level q"
        ]

    def _explain_hochberg_algorithm(self) -> List[str]:
        """Explain Hochberg algorithm step-by-step"""
        return [
            "Algorithm:",
            "1. Sort p-values: p_(1) <= p_(2) <= ... <= p_(m)",
            "2. Find largest k such that p_(k) <= alpha/(m-k+1)",
            "3. Reject all hypotheses with p-values <= p_(k)",
            "Step-up procedure, more powerful than Holm under independence"
        ]

    def _explain_fwer(self, m: int, raw_fwer: float, inflation_factor: float) -> List[str]:
        """Explain Family-Wise Error Rate"""
        return [
            f"FWER is probability of at least one Type I error among {m} tests",
            f"Without correction, FWER inflates to {raw_fwer:.4f} ({inflation_factor:.2f}x nominal)",
            f"Correction methods control FWER at {self.alpha:.2f}",
            "FWER control is critical for confirmatory clinical trials",
            "Required by FDA/EMA for primary endpoint analyses"
        ]

    def _explain_comparison(self, power_ranking: List[Tuple], m: int) -> List[str]:
        """Explain comparison of methods"""
        top_method = power_ranking[0][0] if power_ranking else "None"
        bottom_method = power_ranking[-1][0] if power_ranking else "None"

        return [
            f"Comparing all correction methods for {m} tests",
            f"Most powerful: {top_method.upper()} ({power_ranking[0][1]} significant)",
            f"Most conservative: {bottom_method.upper()} ({power_ranking[-1][1]} significant)",
            "FDR methods generally more powerful than FWER methods",
            "Choice depends on: error rate goal, test dependence, study phase"
        ]

    # ==================== Interpretation Methods ====================

    def _interpret_bonferroni(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str]
    ) -> List[str]:
        """Generate plain language interpretations for Bonferroni"""
        interpretations = [
            "Bonferroni controls family-wise error rate by dividing alpha by number of tests",
            f"With {len(p_values)} tests, significance threshold is {self.alpha/len(p_values):.4f}"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            if sig:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adjusted={adj_p:.4f} - SIGNIFICANT"
                )
            elif p_val <= self.alpha:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adjusted={adj_p:.4f} - not significant after correction"
                )

        return interpretations

    def _interpret_holm(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str], sorted_indices: np.ndarray
    ) -> List[str]:
        """Generate plain language interpretations for Holm"""
        interpretations = [
            "Holm is a step-down procedure that is more powerful than Bonferroni",
            "Tests are ranked by p-value and compared to successively less strict thresholds"
        ]

        for idx, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            rank = np.where(sorted_indices == idx)[0][0] + 1
            if sig:
                interpretations.append(
                    f"{test_names[idx]}: p={p_val:.4f}, adj={adj_p:.4f}, rank={rank} - SIGNIFICANT"
                )

        return interpretations

    def _interpret_bh(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str], q_value: float
    ) -> List[str]:
        """Generate plain language interpretations for Benjamini-Hochberg"""
        interpretations = [
            f"Benjamini-Hochberg controls FDR at {q_value:.2f} (false discovery rate)",
            "Expected {q_value*100:.1f}% of discoveries may be false positives",
            "More powerful than FWER methods, appropriate for exploratory analyses"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            if sig:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adj={adj_p:.4f} - SIGNIFICANT (FDR controlled)"
                )

        return interpretations

    def _interpret_by(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str], q_value: float
    ) -> List[str]:
        """Generate plain language interpretations for Benjamini-Yekutieli"""
        interpretations = [
            f"Benjamini-Yekutieli controls FDR at {q_value:.2f} under arbitrary dependence",
            "More conservative than Benjamini-Hochberg, suitable for correlated tests",
            "Uses harmonic sum correction factor for dependence adjustment"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            if sig:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adj={adj_p:.4f} - SIGNIFICANT (under dependence)"
                )

        return interpretations

    def _interpret_sidak(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str], sidak_alpha: float
    ) -> List[str]:
        """Generate plain language interpretations for Šidák"""
        interpretations = [
            f"Šidák adjusts threshold to {sidak_alpha:.4f} (vs {self.alpha:.4f} for single test)",
            "Slightly less conservative than Bonferroni, assumes test independence",
            "Exact FWER control under independence"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            if sig:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adj={adj_p:.4f} - SIGNIFICANT (independent)"
                )

        return interpretations

    def _interpret_hochberg(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str]
    ) -> List[str]:
        """Generate plain language interpretations for Hochberg"""
        interpretations = [
            "Hochberg is a step-up procedure, more powerful than Holm under independence",
            "Starts from largest p-value, rejects all hypotheses with p-values <= significant one",
            "Requires test independence assumption"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            if sig:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adj={adj_p:.4f} - SIGNIFICANT (step-up)"
                )

        return interpretations

    def _interpret_hommel(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str]
    ) -> List[str]:
        """Generate plain language interpretations for Hommel"""
        interpretations = [
            "Hommel uses closed testing with global test approach",
            "Generally more powerful than Bonferroni and Holm",
            "Suitable for complex multiplicity problems in clinical trials"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            if sig:
                interpretations.append(
                    f"{test_names[i]}: p={p_val:.4f}, adj={adj_p:.4f} - SIGNIFICANT (global test)"
                )

        return interpretations

    def _interpret_general(
        self, p_values: np.ndarray, adjusted_pvals: np.ndarray,
        significant: np.ndarray, test_names: List[str], method: str
    ) -> List[str]:
        """Generate plain language interpretations for general method"""
        method_name = method.upper()
        interpretations = [
            f"Using {method_name} correction for {len(p_values)} tests",
            f"Family-wise error rate controlled at {self.alpha:.2f}"
        ]

        for i, (p_val, adj_p, sig) in enumerate(zip(p_values, adjusted_pvals, significant)):
            status = "SIGNIFICANT" if sig else "not significant"
            interpretations.append(
                f"{test_names[i]}: p={p_val:.4f}, adj={adj_p:.4f} - {status}"
            )

        return interpretations

    def _interpret_fwer(
        self, raw_fwer: float, inflation_factor: float, m: int
    ) -> List[str]:
        """Interpret FWER calculations"""
        return [
            f"Without correction, testing {m} hypotheses inflates FWER to {raw_fwer:.4f}",
            f"This is {inflation_factor:.2f} times the nominal {self.alpha:.2f} level",
            "Correction methods are needed to maintain FWER at the desired level",
            "FWER control is essential for confirmatory clinical trials"
        ]

    def _interpret_comparison(
        self, power_ranking: List[Tuple], m: int
    ) -> List[str]:
        """Interpret comparison results"""
        interpretations = [
            f"Comparison of {len(power_ranking)} correction methods for {m} tests"
        ]

        for method, sig_count in power_ranking:
            interpretations.append(
                f"{method.upper()}: {sig_count} significant findings"
            )

        return interpretations

    # ==================== Clinical Guidance Methods ====================

    def _clinical_guidance_bonferroni(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Bonferroni"""
        return [
            "FDA Guidance (2017): Bonferroni is simple and ensures FWER control",
            "EMA Guideline (2016): May be appropriate for small number of comparisons",
            "Best for: Confirmatory trials with few primary endpoints",
            "Consider when: Regulatory simplicity is preferred over power",
            "Avoid when: Number of tests is very large (>20) leading to power issues"
        ]

    def _clinical_guidance_holm(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Holm-Bonferroni"""
        return [
            "EMA Guideline (2016): Recommended as default stepwise procedure",
            "FDA Guidance (2017): Acceptable for hierarchical endpoint testing",
            "Best for: Primary and secondary endpoint hierarchies",
            "Consider when: More power desired than Bonferroni",
            "Suitable for: Adaptive designs with multiple looks"
        ]

    def _clinical_guidance_bh(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Benjamini-Hochberg"""
        return [
            "FDA Guidance (2017): Appropriate for exploratory analyses",
            "Best for: Biomarker discovery and screening studies",
            "Consider when: Some false positives are acceptable",
            "Not recommended: For confirmatory primary endpoints",
            "Use when: Power is prioritized over strict FWER control"
        ]

    def _clinical_guidance_by(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Benjamini-Yekutieli"""
        return [
            "Use when: Tests are strongly positively correlated",
            "Best for: Repeated measures over time",
            "Consider when: Related biomarkers are analyzed together",
            "Warning: Very conservative, may lose substantial power",
            "Alternative: Use BH if correlation is weak"
        ]

    def _clinical_guidance_sidak(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Šidák"""
        return [
            "Assumes: Complete independence of all tests",
            "Best for: Independent clinical trials pooled in meta-analysis",
            "Consider when: Very slight power improvement needed vs Bonferroni",
            "Warning: Violation of independence invalidates FWER control",
            "Use only: When independence assumption is justified"
        ]

    def _clinical_guidance_hochberg(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Hochberg"""
        return [
            "Requires: Test independence assumption",
            "Best for: Independent secondary endpoint testing",
            "More powerful than Holm under independence",
            "Consider when: Testing multiple independent hypotheses",
            "EMA: Acceptable for confirmatory secondary endpoints"
        ]

    def _clinical_guidance_hommel(self) -> List[str]:
        """Provide FDA/EMA clinical guidance for Hommel"""
        return [
            "FDA Guidance (2017): Powerful option for complex multiplicity",
            "EMA Guideline (2016): Acceptable for confirmatory analyses",
            "Best for: Large clinical trials with many endpoints",
            "Consider when: Maximum power is needed with FWER control",
            "Note: Computationally intensive for very large test sets"
        ]

    def _clinical_guidance_fwer(self) -> List[str]:
        """Provide clinical guidance for FWER control"""
        return [
            "FDA/EMA Requirement: FWER control at 5% for confirmatory trials",
            "Primary endpoints: Must use FWER methods (not FDR)",
            "Secondary endpoints: May use FDR for exploratory analyses",
            "Regulatory expectation: Documented multiplicity adjustment",
            "International Conference on Harmonization (ICH) E9: Recommends FWER control"
        ]

    def _clinical_guidance_comparison(self) -> List[str]:
        """Provide clinical guidance for method comparison"""
        return [
            "Method selection should be pre-specified in analysis plan",
            "Document justification in statistical analysis plan (SAP)",
            "Consider: Study phase, regulatory requirements, scientific goals",
            "Confirmatory: Use FWER methods (Bonferroni, Holm, Hommel)",
            "Exploratory: May use FDR methods (BH, BY)",
            "FDA/EMA: Sensitivity analyses using multiple methods recommended"
        ]

    # ==================== Comparison Helper Methods ====================

    def _compare_by_vs_bh(self, p_values: np.ndarray, m: int) -> Dict[str, float]:
        """Compare Benjamini-Yekutieli vs Benjamini-Hochberg"""
        bh_result = self.benjamini_hochberg_fdr(p_values, q_value=self.alpha)
        by_result = self.benjamini_yekutieli_fdr(p_values, q_value=self.alpha)

        return {
            "bh_significant": bh_result["num_significant"],
            "by_significant": by_result["num_significant"],
            "power_difference": bh_result["num_significant"] - by_result["num_significant"],
            "by_more_conservative": by_result["num_significant"] < bh_result["num_significant"]
        }

    def _compare_sidak_vs_bonferroni(self, m: int) -> Dict[str, float]:
        """Compare Šidák vs Bonferroni thresholds"""
        sidak_alpha = 1 - (1 - self.alpha) ** (1 / m)
        bonferroni_alpha = self.alpha / m

        return {
            "sidak_threshold": sidak_alpha,
            "bonferroni_threshold": bonferroni_alpha,
            "threshold_difference": sidak_alpha - bonferroni_alpha,
            "sidak_less_conservative": sidak_alpha > bonferroni_alpha
        }

    def _compare_hochberg_vs_holm(self, p_values: np.ndarray, m: int) -> Dict[str, float]:
        """Compare Hochberg vs Holm"""
        holm_result = self.holm_bonferroni_correction(p_values)
        hochberg_result = self.hochberg_correction(p_values)

        return {
            "holm_significant": holm_result["num_significant"],
            "hochberg_significant": hochberg_result["num_significant"],
            "hochberg_more_powerful": hochberg_result["num_significant"] > holm_result["num_significant"],
            "requires_independence": True
        }

    def _compare_hommel_vs_bonferroni(self, p_values: np.ndarray, m: int) -> Dict[str, float]:
        """Compare Hommel vs Bonferroni"""
        bonferroni_result = self.bonferroni_correction(p_values)
        hommel_result = self.hommel_correction(p_values)

        return {
            "bonferroni_significant": bonferroni_result["num_significant"],
            "hommel_significant": hommel_result["num_significant"],
            "hommel_more_powerful": hommel_result["num_significant"] > bonferroni_result["num_significant"],
            "power_gain": hommel_result["num_significant"] - bonferroni_result["num_significant"]
        }

    def _assess_conservatism(self, method: str) -> str:
        """Assess conservatism level of method"""
        conservatism_levels = {
            "bonferroni": "very high",
            "sidak": "high",
            "hommel": "moderate",
            "holm": "moderate",
            "hochberg": "low (under independence)",
            "fdr_bh": "low (FDR control)",
            "fdr_by": "high (under dependence)"
        }
        return conservatism_levels.get(method, "unknown")

    def _requires_independence(self, method: str) -> bool:
        """Check if method requires independence assumption"""
        independence_required = ["sidak", "hochberg"]
        return method in independence_required

    def _suitability_confirmatory(self, method: str) -> bool:
        """Check if method is suitable for confirmatory analysis"""
        confirmatory_methods = ["bonferroni", "holm", "hommel", "sidak", "hochberg"]
        return method in confirmatory_methods

    def _suitability_exploratory(self, method: str) -> bool:
        """Check if method is suitable for exploratory analysis"""
        exploratory_methods = ["fdr_bh", "fdr_by", "holm", "hochberg", "hommel"]
        return method in exploratory_methods

    # ==================== Warning Generation ====================

    def _generate_warnings(self, method: str, m: int) -> List[str]:
        """Generate warnings for specific methods"""
        warnings = []

        # General warnings
        if m > 20 and method in ["bonferroni"]:
            warnings.append(
                f"WARNING: Bonferroni with {m} tests may be severely underpowered. "
                "Consider Holm or Hommel."
            )

        if m > 50 and method in ["hommel"]:
            warnings.append(
                f"WARNING: Hommel with {m} tests may be slow computationally. "
                "Consider Holm or Hochberg."
            )

        # Method-specific warnings
        if method == "sidak":
            warnings.append(
                "CRITICAL: Šidák assumes complete test independence. "
                "Do not use with correlated endpoints."
            )

        if method == "hochberg":
            warnings.append(
                "WARNING: Hochberg assumes test independence. "
                "Use Holm if correlation is suspected."
            )

        if method == "fdr_by":
            warnings.append(
                f"NOTE: Benjamini-Yekutieli is very conservative with {m} tests. "
                "Consider Benjamini-Hochberg if correlation is weak."
            )

        if method in ["fdr_bh", "fdr_by"]:
            warnings.append(
                "IMPORTANT: FDR methods do NOT control FWER. "
                "Not appropriate for confirmatory primary endpoints."
            )

        if m < 3 and method in ["holm", "hochberg", "hommel"]:
            warnings.append(
                "NOTE: With few tests, differences between methods are minimal. "
                "Bonferroni may be sufficient for simplicity."
            )

        return warnings

    # ==================== Method Recommendations ====================

    def _generate_method_recommendations(
        self, p_values: np.ndarray, m: int
    ) -> List[Dict[str, Any]]:
        """Generate method recommendations based on data"""
        recommendations = []

        # Analyze p-values
        small_count = np.sum(p_values < 0.01)
        medium_count = np.sum((p_values >= 0.01) & (p_values < 0.05))
        large_count = np.sum(p_values >= 0.05)

        # Confirmatory analysis (FWER methods)
        recommendations.append({
            "scenario": "Confirmatory Clinical Trial (Primary Endpoints)",
            "recommended": "Holm-Bonferroni",
            "alternative": "Hommel",
            "reasoning": (
                "EMA recommends Holm as default stepwise procedure. "
                "Hommel provides more power for larger test sets. "
                "FWER control is required by FDA/EMA."
            ),
            "avoid": ["fdr_bh", "fdr_by"]
        })

        # Exploratory analysis (FDR methods)
        recommendations.append({
            "scenario": "Exploratory Biomarker Discovery",
            "recommended": "Benjamini-Hochberg (FDR)",
            "alternative": "Benjamini-Yekutieli (if correlated)",
            "reasoning": (
                "FDR control is more powerful for discovery. "
                "Some false positives are acceptable in exploratory work. "
                "BH is standard in genomics and biomarker studies."
            ),
            "avoid": ["bonferroni"]
        })

        # Hierarchical testing
        recommendations.append({
            "scenario": "Hierarchical Endpoint Testing",
            "recommended": "Holm-Bonferroni",
            "alternative": "Fixed sequence",
            "reasoning": (
                "Holm naturally handles ordered hypotheses. "
                "EMA recommends fixed sequence for prespecified hierarchies. "
                "Power is improved by testing most important endpoints first."
            ),
            "avoid": ["bonferroni"]
        })

        # Independent tests
        recommendations.append({
            "scenario": "Independent Tests (Justified)",
            "recommended": "Šidák or Hochberg",
            "alternative": "Holm (conservative choice)",
            "reasoning": (
                "Šidák and Hochberg are more powerful under independence. "
                "Use Šidák for slight power gain. "
                "Use Hochberg for step-up procedure."
            ),
            "requires": "Independence assumption justification"
        })

        # Large test sets
        if m > 50:
            recommendations.append({
                "scenario": "Large Test Set (50+ tests)",
                "recommended": "Benjamini-Hochberg (FDR) or Hommel",
                "alternative": "Holm (for confirmatory)",
                "reasoning": (
                    f"Bonferroni will be severely underpowered with {m} tests. "
                    "Hommel may be slow computationally. "
                    "FDR is most powerful for large test sets."
                ),
                "avoid": ["bonferroni", "sidak"]
            })

        # Correlated endpoints
        recommendations.append({
            "scenario": "Correlated Endpoints",
            "recommended": "Holm or Hommel",
            "alternative": "Benjamini-Yekutieli (if FDR acceptable)",
            "reasoning": (
                "These methods handle arbitrary correlation. "
                "Avoid Šidák and Hochberg which assume independence. "
                "BY controls FDR under positive dependence."
            ),
            "avoid": ["sidak", "hochberg"]
        })

        # Regulatory simplicity
        recommendations.append({
            "scenario": "Regulatory Simplicity Priority",
            "recommended": "Bonferroni",
            "alternative": "Holm",
            "reasoning": (
                "Bonferroni is simplest to explain to regulators. "
                "FDA/EMA accept both methods. "
                "Use when simplicity outweighs power loss."
            ),
            "condition": "Few tests (<10) and sufficient power"
        })

        return recommendations

    # ==================== Additional Utility Methods ====================

    def get_analysis_summary(self) -> Dict[str, Any]:
        """Get summary of all analyses performed"""
        if not self.analysis_history:
            return {"message": "No analyses performed yet"}

        methods_used = [a["method"] for a in self.analysis_history]
        method_counts = {m: methods_used.count(m) for m in set(methods_used)}

        return {
            "total_analyses": len(self.analysis_history),
            "methods_used": method_counts,
            "tests_performed": sum(a["num_tests"] for a in self.analysis_history),
            "significant_findings": sum(a["num_significant"] for a in self.analysis_history),
            "alpha_level": self.alpha,
            "analysis_history": self.analysis_history
        }

    def reset_history(self) -> None:
        """Reset analysis history"""
        self.analysis_history = []

    def __repr__(self) -> str:
        """String representation of the multiplicity control engine"""
        return (
            f"MultiplicityControl(alpha={self.alpha}, "
            f"independence={self.independence}, "
            f"analyses={len(self.analysis_history)})"
        )


# ==================== Module Information ====================

__all__ = [
    "MultiplicityControl",
]

__version__ = "1.0.0"
__author__ = "BioDockify AI - Statistics Team"
__license__ = "MIT"
__description__ = (
    "Comprehensive multiplicity control for pharmaceutical statistics, "
    "providing FDA/EMA compliant multiple testing corrections"
)
