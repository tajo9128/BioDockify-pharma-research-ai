"""Multiplicity Control Module for Pharmaceutical Statistics

Provides comprehensive multiplicity correction methods for controlling
Type I error rates in clinical trial analyses.

Complies with:
- Good Laboratory Practice (GLP)
- Good Clinical Practice (GCP)
- FDA Multiplicity Adjustments in Clinical Trials Guidance (2019)
- EMA Guideline on Multiplicity Issues in Clinical Trials (2016)
- ICH E9 Statistical Principles for Clinical Trials

Reference:
- FDA: "Multiplicity Adjustments in Clinical Trials" (July 2017)
- EMA: "Guideline on Multiplicity Issues in Clinical Trials" (December 2016)
- Benjamini & Hochberg (1995): Controlling the False Discovery Rate
- Holm (1979): A Simple Sequentially Rejective Multiple Test Procedure
- Šidák (1967): Rectangular Confidence Regions for the Means
"""

import numpy as np
import pandas as pd
from scipy import stats
import statsmodels.stats.multitest as smm
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')


class MultiplicityControl:
    """Comprehensive multiplicity control for pharmaceutical statistics

    Provides multiple testing correction methods for:
    - Family-wise error rate (FWER) control
    - False discovery rate (FDR) control
    - Clinical trial multiplicity adjustments
    - Multiple endpoints analysis
    - Subgroup analyses
    - Interim analyses

    Methods:
        bonferroni_correction: Bonferroni correction (conservative)
        holm_bonferroni_correction: Holm step-down (more powerful)
        benjamini_hochberg_fdr: FDR control (BH procedure)
        benjamini_yekutieli_fdr: FDR under dependence
        sidak_correction: Šidák correction (independent tests)
        hochberg_correction: Hochberg step-up procedure
        hommel_correction: Hommel correction (global test)
        calculate_adjusted_pvalues: Unified p-value adjustment
        family_wise_error_rate: FWER calculation and control
        compare_correction_methods: Comparative analysis
    """

    def __init__(self, alpha: float = 0.05, independence: bool = True):
        """Initialize multiplicity control engine

        Args:
            alpha: Family-wise error rate (default: 0.05)
            independence: Assume test independence (affects method selection)
        """
        self.alpha = alpha
        self.independence = independence
        self.analysis_history = []
        self.supported_methods = [
            'bonferroni', 'holm', 'fdr_bh', 'fdr_by',
            'sidak', 'hochberg', 'hommel'
        ]

    def bonferroni_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Bonferroni correction for multiple comparisons

        The Bonferroni correction controls the family-wise error rate (FWER)
        at level α by rejecting hypotheses with p-values ≤ α/m, where m is
        the number of tests. This method is conservative but simple.

        Clinical Application:
            - Multiple primary endpoints in clinical trials
            - Multiple dose groups comparisons
            - Multiple time point analyses

        FDA Guidance: "The Bonferroni method is simple and ensures FWER control,
        but can be conservative when there are many tests."

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations

        Example:
            >>> mc = MultiplicityControl(alpha=0.05)
            >>> pvals = [0.01, 0.02, 0.03, 0.04, 0.05]
            >>> result = mc.bonferroni_correction(pvals)
            >>> # Test 1: 0.01 * 5 = 0.05 (significant)
            >>> # Test 2: 0.02 * 5 = 0.10 (not significant)
        """
        # Input validation
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Bonferroni correction
        adjusted_pvals = np.minimum(p_values * m, 1.0)
        significant = adjusted_pvals <= self.alpha

        # Calculate family-wise error rate
        fwer = self._calculate_fwer(p_values, 'bonferroni')

        # Calculate power loss
        power_loss = self._estimate_power_loss(p_values, m)

        results = {
            'method': 'Bonferroni Correction',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'independence_assumed': False,  # Works for correlated tests
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': adjusted_pvals.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fwer_control': fwer,
            'power_loss_estimate': power_loss,
            'explanations': self._explain_bonferroni(m, fwer),
            'interpretations': self._interpret_bonferroni(
                p_values, adjusted_pvals, significant, test_names
            ),
            'clinical_guidance': self._clinical_guidance_bonferroni(),
            'warnings': self._generate_warnings('bonferroni', m),
            'formula': 'p_adj = min(p × m, 1.0)',
            'reference': 'Bonferroni (1936); FDA Multiplicity Guidance (2017)'
        }

        self._log_analysis('bonferroni', results)
        return results

    def holm_bonferroni_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Holm-Bonferroni step-down procedure

        The Holm-Bonferroni method is a sequentially rejective procedure that
        is uniformly more powerful than the Bonferroni correction while still
        controlling FWER. P-values are sorted, and the smallest is compared
        to α/m, the next to α/(m-1), etc.

        Clinical Application:
            - Hierarchical testing of secondary endpoints
            - Multiple dose comparisons when doses are ordered
            - Adaptive designs with multiple looks

        EMA Guideline: "The Holm procedure is recommended when a stepwise
        procedure is appropriate and more power is desired than Bonferroni."

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations

        Example:
            >>> mc = MultiplicityControl(alpha=0.05)
            >>> pvals = [0.01, 0.02, 0.03, 0.04, 0.05]
            >>> result = mc.holm_bonferroni_correction(pvals)
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Holm-Bonferroni using statsmodels
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method='holm'
        )

        # Get order statistics
        sorted_indices = np.argsort(p_values)
        original_order = np.argsort(sorted_indices)

        significant = reject
        fwer = self._calculate_fwer(p_values, 'holm')
        power_loss = self._estimate_power_loss(p_values, m)

        results = {
            'method': 'Holm-Bonferroni Step-Down',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'independence_assumed': False,
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': pvals_corrected.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fwer_control': fwer,
            'power_loss_estimate': power_loss,
            'sorted_indices': sorted_indices.tolist(),
            'explanations': self._explain_holm(m, fwer),
            'interpretations': self._interpret_holm(
                p_values, pvals_corrected, significant, test_names, sorted_indices
            ),
            'clinical_guidance': self._clinical_guidance_holm(),
            'warnings': self._generate_warnings('holm', m),
            'algorithm': self._explain_holm_algorithm(),
            'reference': 'Holm (1979); EMA Multiplicity Guideline (2016)'
        }

        self._log_analysis('holm', results)
        return results

    def benjamini_hochberg_fdr(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None,
        q_value: float = 0.05
    ) -> Dict[str, Any]:
        """False Discovery Rate control using Benjamini-Hochberg

        The Benjamini-Hochberg procedure controls the expected proportion
        of false discoveries (FDR) rather than FWER. This is less conservative
        and more powerful, making it suitable for exploratory analyses.

        Clinical Application:
            - Biomarker discovery studies
            - High-throughput screening
            - Gene expression analysis
            - Exploratory subgroup analyses

        FDA Guidance: "FDR methods may be appropriate for exploratory analyses
        where some false positives are acceptable."

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test
            q_value: False discovery rate level (default: 0.05)

        Returns:
            Dictionary with corrected p-values and interpretations

        Example:
            >>> mc = MultiplicityControl(alpha=0.05)
            >>> pvals = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]
            >>> result = mc.benjamini_hochberg_fdr(pvals, q_value=0.10)
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Benjamini-Hochberg
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=q_value,
            method='fdr_bh'
        )

        significant = reject
        fdr_estimate = np.mean(pvals_corrected[pvals_corrected <= q_value]) if np.any(significant) else 0
        power_gain = self._estimate_power_gain_vs_bonferroni(p_values, m)

        results = {
            'method': 'Benjamini-Hochberg FDR Control',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'q_value': q_value,
            'num_tests': m,
            'independence_assumed': True,
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': pvals_corrected.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fdr_estimate': fdr_estimate,
            'power_gain_vs_bonferroni': power_gain,
            'explanations': self._explain_bh(m, q_value),
            'interpretations': self._interpret_bh(
                p_values, pvals_corrected, significant, test_names, q_value
            ),
            'clinical_guidance': self._clinical_guidance_bh(),
            'warnings': self._generate_warnings('fdr_bh', m),
            'algorithm': self._explain_bh_algorithm(),
            'reference': 'Benjamini & Hochberg (1995); FDA Multiplicity Guidance (2017)'
        }

        self._log_analysis('fdr_bh', results)
        return results

    def benjamini_yekutieli_fdr(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None,
        q_value: float = 0.05
    ) -> Dict[str, Any]:
        """FDR control under dependence (Benjamini-Yekutieli)

        The Benjamini-Yekutieli procedure controls FDR under arbitrary
        dependence structures. It is more conservative than BH but
        provides valid FDR control when tests are correlated.

        Clinical Application:
            - Correlated endpoints (e.g., related biomarkers)
            - Repeated measures over time
            - Clustered data structures

        Note: This method is very conservative and recommended only when
        strong positive dependence is suspected.

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test
            q_value: False discovery rate level (default: 0.05)

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Benjamini-Yekutieli
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=q_value,
            method='fdr_by'
        )

        significant = reject
        harmonic_sum = np.sum(1 / np.arange(1, m + 1))
        conservativism_factor = harmonic_sum / np.log(m)
        power_vs_bh = self._compare_by_vs_bh(p_values, m)

        results = {
            'method': 'Benjamini-Yekutieli FDR Control',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'q_value': q_value,
            'num_tests': m,
            'independence_assumed': False,  # Handles arbitrary dependence
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': pvals_corrected.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'harmonic_sum': harmonic_sum,
            'conservatism_factor': conservativism_factor,
            'power_vs_bh': power_vs_bh,
            'explanations': self._explain_by(m, q_value, harmonic_sum),
            'interpretations': self._interpret_by(
                p_values, pvals_corrected, significant, test_names, q_value
            ),
            'clinical_guidance': self._clinical_guidance_by(),
            'warnings': self._generate_warnings('fdr_by', m),
            'reference': 'Benjamini & Yekutieli (2001)'
        }

        self._log_analysis('fdr_by', results)
        return results

    def sidak_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Šidák correction for independent tests

        The Šidák correction provides exact FWER control for independent
        tests using the formula α' = 1 - (1 - α)^(1/m). It is slightly
        less conservative than Bonferroni but requires independence.

        Clinical Application:
            - Multiple independent primary endpoints
            - Separate clinical trials pooled in meta-analysis
            - Independent subgroup analyses

        Note: Assumes test independence. Do not use with correlated endpoints.

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Šidák correction
        sidak_alpha = 1 - (1 - self.alpha) ** (1 / m)
        adjusted_pvals = 1 - (1 - np.array(p_values)) ** m
        adjusted_pvals = np.minimum(adjusted_pvals, 1.0)
        significant = p_values <= sidak_alpha

        fwer = self._calculate_fwer(p_values, 'sidak')
        power_vs_bonferroni = self._compare_sidak_vs_bonferroni(m)

        results = {
            'method': 'Šidák Correction',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'independence_assumed': True,  # Critical assumption
            'sidak_alpha': sidak_alpha,
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': adjusted_pvals.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fwer_control': fwer,
            'power_vs_bonferroni': power_vs_bonferroni,
            'explanations': self._explain_sidak(m, sidak_alpha),
            'interpretations': self._interpret_sidak(
                p_values, adjusted_pvals, significant, test_names, sidak_alpha
            ),
            'clinical_guidance': self._clinical_guidance_sidak(),
            'warnings': self._generate_warnings('sidak', m),
            'formula': f'p_adj = 1 - (1 - p)^{m}, α_adj = 1 - (1 - α)^{{1/{m}}}',
            'reference': 'Šidák (1967)'
        }

        self._log_analysis('sidak', results)
        return results

    def hochberg_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Hochberg step-up procedure

        The Hochberg procedure is a step-up method that is more powerful
        than Holm when tests are independent. It starts with the largest
        p-value and works upward, stopping when a significance is found.

        Clinical Application:
            - Multiple comparisons when independence holds
            - Independent secondary endpoint testing
            - Dose-response studies with independent comparisons

        Note: More powerful than Holm under independence but less
        powerful if tests are positively correlated.

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Hochberg correction
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method='hochberg'
        )

        significant = reject
        fwer = self._calculate_fwer(p_values, 'hochberg')
        power_vs_holm = self._compare_hochberg_vs_holm(p_values, m)

        results = {
            'method': 'Hochberg Step-Up Procedure',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'independence_assumed': True,
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': pvals_corrected.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fwer_control': fwer,
            'power_vs_holm': power_vs_holm,
            'explanations': self._explain_hochberg(m, fwer),
            'interpretations': self._interpret_hochberg(
                p_values, pvals_corrected, significant, test_names
            ),
            'clinical_guidance': self._clinical_guidance_hochberg(),
            'warnings': self._generate_warnings('hochberg', m),
            'algorithm': self._explain_hochberg_algorithm(),
            'reference': 'Hochberg (1988)'
        }

        self._log_analysis('hochberg', results)
        return results

    def hommel_correction(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Hommel correction (more powerful than Bonferroni)

        Hommel's method provides exact control of FWER and is generally
        more powerful than Bonferroni and Holm. It's particularly useful
        when there are many tests with small p-values.

        Clinical Application:
            - Multiple primary endpoints with correlation
            - Large clinical trial analyses
            - Complex multiplicity problems

        Note: Computationally intensive for very large numbers of tests (>1000).

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test

        Returns:
            Dictionary with corrected p-values and interpretations
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply Hommel correction
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method='hommel'
        )

        significant = reject
        fwer = self._calculate_fwer(p_values, 'hommel')
        power_vs_bonferroni = self._compare_hommel_vs_bonferroni(p_values, m)

        results = {
            'method': 'Hommel Correction',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'independence_assumed': False,
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': pvals_corrected.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fwer_control': fwer,
            'power_vs_bonferroni': power_vs_bonferroni,
            'explanations': self._explain_hommel(m, fwer),
            'interpretations': self._interpret_hommel(
                p_values, pvals_corrected, significant, test_names
            ),
            'clinical_guidance': self._clinical_guidance_hommel(),
            'warnings': self._generate_warnings('hommel', m),
            'reference': 'Hommel (1988)'
        }

        self._log_analysis('hommel', results)
        return results

    def calculate_adjusted_pvalues(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        method: str = 'holm',
        test_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Calculate adjusted p-values using specified method

        Unified interface for multiple testing correction supporting
        all major methods. Provides consistent output format for
        easy comparison across methods.

        Supported Methods:
            - 'bonferroni': Bonferroni correction (most conservative)
            - 'holm': Holm step-down (recommended default)
            - 'fdr_bh': Benjamini-Hochberg FDR (exploratory)
            - 'fdr_by': Benjamini-Yekutieli FDR (dependent)
            - 'sidak': Šidák (independent only)
            - 'hochberg': Hochberg step-up (independent)
            - 'hommel': Hommel (more powerful)

        Args:
            p_values: Array of p-values from multiple tests
            method: Correction method (default: 'holm')
            test_names: Optional names for each test

        Returns:
            Dictionary with adjusted p-values and interpretations

        Raises:
            ValueError: If method is not supported
        """
        if method not in self.supported_methods:
            raise ValueError(
                f"Method '{method}' not supported. "
                f"Choose from: {', '.join(self.supported_methods)}"
            )

        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        # Apply selected correction
        reject, pvals_corrected, _, _ = smm.multipletests(
            p_values,
            alpha=self.alpha,
            method=method
        )

        significant = reject
        fwer = self._calculate_fwer(p_values, method)

        results = {
            'method': f'{method.upper()} Correction',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'correction_method': method,
            'num_tests': m,
            'original_pvalues': p_values.tolist(),
            'adjusted_pvalues': pvals_corrected.tolist(),
            'test_names': test_names,
            'significant': significant.tolist(),
            'num_significant': int(np.sum(significant)),
            'fwer_control': fwer,
            'explanations': self._explain_method(method, m),
            'interpretations': self._interpret_general(
                p_values, pvals_corrected, significant, test_names, method
            ),
            'warnings': self._generate_warnings(method, m)
        }

        self._log_analysis(method, results)
        return results

    def family_wise_error_rate(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        method: str = 'bonferroni'
    ) -> Dict[str, Any]:
        """Calculate and control Family-Wise Error Rate (FWER)

        FWER is the probability of making at least one Type I error
        (false positive) among all hypotheses tested. This method
        provides detailed FWER calculations and control strategies.

        Clinical Importance:
            - Critical for confirmatory trials
            - Required by FDA/EMA for primary endpoints
            - Ensures overall study integrity

        Args:
            p_values: Array of p-values from multiple tests
            method: FWER control method

        Returns:
            Dictionary with FWER calculations and control
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        # Calculate raw FWER (probability of at least one Type I error)
        raw_fwer = 1 - (1 - self.alpha) ** m
        bonferroni_fwer = min(self.alpha * m, 1.0)
        sidak_fwer = 1 - (1 - self.alpha) ** m

        # Simulate FWER under independence
        simulated_fwer = self._simulate_fwer(m, n_simulations=10000)

        results = {
            'method': 'Family-Wise Error Rate Analysis',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'fwer_calculations': {
                'nominal_fwer': self.alpha,
                'raw_fwer_inflation': raw_fwer,
                'bonferroni_controlled': bonferroni_fwer,
                'sidak_controlled': sidak_fwer,
                'simulated_fwer': simulated_fwer
            },
            'explanations': {
                'fwer_definition': (
                    'Family-wise error rate (FWER) is the probability of '
                    'making at least one Type I error (false positive) among '
                    'all hypotheses tested.'
                ),
                'inflation_risk': (
                    f'Without correction, testing {m} hypotheses at α={self.alpha} '
                    f'inflates FWER to {raw_fwer:.4f} ({raw_fwer/self.alpha:.1f}× higher)'
                ),
                'control_methods': (
                    'Multiple methods control FWER: Bonferroni (simple but '
                    'conservative), Šidák (exact under independence), '
                    'Holm/Hommel (more powerful), and others.'
                )
            },
            'interpretations': {
                'clinical_significance': (
                    'FWER control is essential for confirmatory trials where '
                    'false positive findings could lead to inappropriate '
                    'treatment approvals.'
                ),
                'regulatory_requirement': (
                    'FDA and EMA require FWER control for primary efficacy '
                    'endpoints in Phase III confirmatory trials.'
                )
            },
            'clinical_guidance': self._clinical_guidance_fwer(),
            'reference': 'ICH E9; FDA Multiplicity Guidance (2017)'
        }

        self._log_analysis('fwer', results)
        return results

    def compare_correction_methods(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series],
        test_names: Optional[List[str]] = None,
        methods: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Compare different multiplicity correction methods

        Comprehensive comparison of all available correction methods
        including power, conservativism, and suitability for different
        clinical trial scenarios.

        Comparison Metrics:
            - Number of significant findings
            - Adjusted p-values
            - Power estimates
            - Conservativism ranking
            - Clinical trial suitability

        Args:
            p_values: Array of p-values from multiple tests
            test_names: Optional names for each test
            methods: List of methods to compare (None = all)

        Returns:
            Dictionary with comprehensive comparison
        """
        p_values = self._validate_pvalues(p_values)
        m = len(p_values)

        if test_names is None:
            test_names = [f"Test_{i+1}" for i in range(m)]

        if methods is None:
            methods = ['bonferroni', 'holm', 'fdr_bh', 'sidak', 'hochberg', 'hommel']

        # Apply all methods
        comparison_results = {}
        num_significant = {}
        adjusted_pvals = {}

        for method in methods:
            try:
                reject, pvals_corrected, _, _ = smm.multipletests(
                    p_values, alpha=self.alpha, method=method
                )
                comparison_results[method] = {
                    'adjusted_pvalues': pvals_corrected.tolist(),
                    'significant': reject.tolist(),
                    'num_significant': int(np.sum(reject))
                }
                num_significant[method] = int(np.sum(reject))
                adjusted_pvals[method] = pvals_corrected
            except Exception as e:
                comparison_results[method] = {'error': str(e)}

        # Rank methods by power (number of significant findings)
        ranked_methods = sorted(
            num_significant.items(),
            key=lambda x: x[1],
            reverse=True
        )

        # Calculate correlation between methods
        correlation_matrix = self._calculate_method_correlation(
            adjusted_pvals
        )

        # Generate comparison table
        comparison_table = pd.DataFrame({
            'Method': methods,
            'Num_Significant': [num_significant.get(m, 0) for m in methods],
            'Conservatism': [self._assess_conservatism(m) for m in methods],
            'Independence_Required': [
                self._requires_independence(m) for m in methods
            ],
            'Suitability_Confirmatory': [
                self._suitability_confirmatory(m) for m in methods
            ],
            'Suitability_Exploratory': [
                self._suitability_exploratory(m) for m in methods
            ]
        })

        results = {
            'comparison_type': 'Multiplicity Correction Methods',
            'timestamp': datetime.now().isoformat(),
            'alpha': self.alpha,
            'num_tests': m,
            'test_names': test_names,
            'methods_compared': methods,
            'results_by_method': comparison_results,
            'num_significant_by_method': num_significant,
            'power_ranking': ranked_methods,
            'correlation_matrix': correlation_matrix,
            'comparison_table': comparison_table.to_dict('records'),
            'method_recommendations': self._generate_method_recommendations(
                p_values, m
            ),
            'explanations': self._explain_comparison(ranked_methods, m),
            'clinical_guidance': self._clinical_guidance_comparison(),
            'reference': 'FDA/EMA Multiplicity Guidelines'
        }

        self._log_analysis('comparison', results)
        return results

    # ==============================================================================
    # HELPER METHODS - Internal utilities
    # ==============================================================================

    def _validate_pvalues(
        self,
        p_values: Union[List[float], np.ndarray, pd.Series]
    ) -> np.ndarray:
        """Validate and convert p-values to numpy array

        Args:
            p_values: Input p-values

        Returns:
            Validated numpy array of p-values

        Raises:
            ValueError: If p-values are invalid
        """
        if isinstance(p_values, (list, tuple)):
            p_values = np.array(p_values)
        elif isinstance(p_values, pd.Series):
            p_values = p_values.values

        # Check for valid values
        if not isinstance(p_values, np.ndarray):
            raise ValueError("p_values must be list, array, or Series")

        if len(p_values) == 0:
            raise ValueError("p_values cannot be empty")

        if np.any(p_values < 0) or np.any(p_values > 1):
            raise ValueError("p_values must be in range [0, 1]")

        if np.any(np.isnan(p_values)):
            raise ValueError("p_values cannot contain NaN values")

        return p_values

    def _calculate_fwer(
        self,
        p_values: np.ndarray,
        method: str
    ) -> Dict[str, float]:
        """Calculate family-wise error rate for a method

        Args:
            p_values: P-values
            method: Correction method

        Returns:
            Dictionary with FWER metrics
        """
        m = len(p_values)
        nominal_fwer = self.alpha
        inflated_fwer = 1 - (1 - self.alpha) ** m

        # Calculate control factor
        if method == 'bonferroni':
            control_factor = 1.0 / m
        elif method == 'sidak':
            control_factor = 1 - (1 - self.alpha) ** (1 / m) / self.alpha
        elif method in ['holm', 'hochberg', 'hommel']:
            control_factor = 1.0 / m  # Approximate
        else:
            control_factor = 1.0 / m

        return {
            'nominal_alpha': nominal_fwer,
            'inflated_fwer': inflated_fwer,
            'inflation_ratio': inflated_fwer / nominal_fwer,
            'control_factor': control_factor,
            'controlled_fwer': nominal_fwer * control_factor
        }

    def _estimate_power_loss(
        self,
        p_values: np.ndarray,
        m: int
    ) -> Dict[str, float]:
        """Estimate power loss relative to no correction

        Args:
            p_values: P-values
            m: Number of tests

        Returns:
            Power loss estimates
        """
        # Count significant at nominal level
        nom_sig = np.sum(p_values <= self.alpha)

        # Estimate corrected significance
        adj_threshold = self.alpha / m
        adj_sig = np.sum(p_values <= adj_threshold)

        return {
            'nominal_significant': int(nom_sig),
            'corrected_significant_estimate': int(adj_sig),
            'power_loss_ratio': 1 - (adj_sig / nom_sig) if nom_sig > 0 else 0.0,
            'threshold_ratio': adj_threshold / self.alpha
        }

    def _estimate_power_gain_vs_bonferroni(
        self,
        p_values: np.ndarray,
        m: int
    ) -> Dict[str, float]:
        """Estimate power gain of BH vs Bonferroni

        Args:
            p_values: P-values
            m: Number of tests

        Returns:
            Power gain estimates
        """
        bonf_threshold = self.alpha / m
        bonf_sig = np.sum(p_values <= bonf_threshold)

        # BH is more lenient
        bh_sig = np.sum(
            smm.multipletests(p_values, alpha=self.alpha, method='fdr_bh')[0]
        )

        return {
            'bonferroni_significant': int(bonf_sig),
            'bh_significant': int(bh_sig),
            'power_gain': int(bh_sig - bonf_sig),
            'relative_increase': (
                (bh_sig - bonf_sig) / bonf_sig if bonf_sig > 0 else 0.0
            )
        }

    def _simulate_fwer(
        self,
        m: int,
        n_simulations: int = 10000
    ) -> float:
        """Simulate FWER under null hypothesis

        Args:
            m: Number of tests
            n_simulations: Number of simulations

        Returns:
            Simulated FWER
        """
        np.random.seed(42)
        null_pvals = np.random.uniform(0, 1, (n_simulations, m))
        false_positives = np.any(null_pvals <= self.alpha, axis=1)
        return np.mean(false_positives)

    def _calculate_method_correlation(
        self,
        adjusted_pvals: Dict[str, np.ndarray]
    ) -> Dict[str, Dict[str, float]]:
        """Calculate correlation between methods

        Args:
            adjusted_pvals: Dictionary of adjusted p-values

        Returns:
            Correlation matrix
        """
        methods = list(adjusted_pvals.keys())
        correlation = {}

        for i, method1 in enumerate(methods):
            correlation[method1] = {}
            for method2 in methods:
                if i == len(correlation) - 1:
                    corr = 1.0
                else:
                    corr = float(np.corrcoef(
                        adjusted_pvals[method1],
                        adjusted_pvals[method2]
                    )[0, 1])
                correlation[method1][method2] = round(corr, 4)

        return correlation

    # ==============================================================================
    # EXPLANATION METHODS - Generate detailed explanations
    # ==============================================================================

    def _explain_bonferroni(self, m: int, fwer: Dict) -> Dict[str, str]:
        """Generate Bonferroni explanations"""
        return {
            'method_description': (
                'Bonferroni correction divides the significance level α '
                f'by the number of tests (m={m}). This ensures the family-wise '
                'error rate is controlled at level α.'
            ),
            'formula_explanation': (
                f'Adjusted α = {self.alpha} / {m} = {self.alpha/m:.6f}\n'
                f'Adjusted p-value = p × {m}\n'
                'Reject if p ≤ α/m'
            ),
            'advantages': (
                '- Simple and intuitive\n'
                '- Controls FWER exactly for any correlation structure\n'
                '- Widely accepted by regulators\n'
                '- No assumptions about test independence'
            ),
            'disadvantages': (
                f'- Conservative, especially with many tests (m={m})\n'
                '- Reduces power substantially\n'
                '- May miss true effects'
            ),
            'when_to_use': (
                '- Small number of tests (≤5)\n'
                '- Confirmatory clinical trials\n'
                '- Primary endpoint analysis\n'
                '- When conservativism is acceptable'
            )
        }

    def _interpret_bonferroni(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str]
    ) -> Dict[str, str]:
        """Generate Bonferroni interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        if num_sig == 0:
            interpretations['overall'] = (
                f'No tests remain significant after Bonferroni correction. '
                f'This indicates either no true effects or insufficient power '
                f'with {len(p_values)} tests.'
            )
        elif num_sig < len(p_values) * 0.5:
            interpretations['overall'] = (
                f'{num_sig} of {len(p_values)} tests ({num_sig/len(p_values)*100:.1f}%) '
                f'remain significant after correction. Suggests moderate evidence '
                f'but may be underpowered.'
            )
        else:
            interpretations['overall'] = (
                f'{num_sig} of {len(p_values)} tests ({num_sig/len(p_values)*100:.1f}%) '
                f'remain significant. Strong evidence for multiple effects.'
            )

        interpretations['individual'] = []
        for i, (p, adj_p, sig, name) in enumerate(
            zip(p_values, adjusted_pvals, significant, test_names)
        ):
            if sig:
                interpretations['individual'].append(
                    f'{name}: Original p={p:.4f}, Adjusted p={adj_p:.4f} - '
                    'REMAINS SIGNIFICANT (strong evidence)'
                )
            elif p < 0.05:
                interpretations['individual'].append(
                    f'{name}: Original p={p:.4f}, Adjusted p={adj_p:.4f} - '
                    'LOST SIGNIFICANCE (Bonferroni is conservative)'
                )

        return interpretations

    def _explain_holm(self, m: int, fwer: Dict) -> Dict[str, str]:
        """Generate Holm explanations"""
        return {
            'method_description': (
                'Holm-Bonferroni is a step-down procedure that is uniformly '
                'more powerful than Bonferroni while still controlling FWER. '
                f'P-values are sorted and tested sequentially against α/{m}, '
                f'α/{m-1}, α/{m-2}, etc.'
            ),
            'algorithm': (
                '1. Sort p-values: p(1) ≤ p(2) ≤ ... ≤ p(m)\n'
                '2. Compare p(1) to α/m\n'
                '3. If significant, compare p(2) to α/(m-1)\n'
                '4. Continue until first non-significant\n'
                '5. Reject all previous hypotheses'
            ),
            'advantages': (
                '- More powerful than Bonferroni\n'
                '- Still controls FWER exactly\n'
                '- No independence assumption\n'
                '- Computationally simple'
            ),
            'disadvantages': (
                '- Still conservative with many tests\n'
                '- Less powerful than Hochberg under independence'
            ),
            'when_to_use': (
                '- Default choice for FWER control\n'
                '- Multiple comparisons with moderate m\n'
                '- When more power than Bonferroni is needed\n'
                '- Recommended by EMA for secondary endpoints'
            )
        }

    def _explain_holm_algorithm(self) -> str:
        """Detailed Holm algorithm explanation"""
        return (
            'Holm Step-Down Algorithm:\n'
            '========================\n'
            '1. Order p-values: p(1) ≤ p(2) ≤ ... ≤ p(m)\n'
            '2. For k = 1 to m:\n'
            '   a. Compare p(k) to α/(m-k+1)\n'
            '   b. If p(k) > α/(m-k+1): STOP, do not reject H(k)...H(m)\n'
            '   c. If p(k) ≤ α/(m-k+1): Reject H(k), continue to k+1\n'
            '3. Reject all H(1), ..., H(j) where j is last rejected\n\n'
            'This sequential testing provides more power than Bonferroni '
            'while maintaining strict FWER control.'
        )

    def _interpret_holm(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str],
        sorted_indices: np.ndarray
    ) -> Dict[str, str]:
        """Generate Holm interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        if num_sig == 0:
            interpretations['overall'] = (
                'No tests remain significant after Holm correction. '
                'The sequential testing did not find sufficient evidence '
                'to reject any hypotheses.'
            )
        else:
            smallest_p = p_values[sorted_indices[0]]
            interpretations['overall'] = (
                f'{num_sig} tests significant. The sequential procedure '
                f'found evidence starting from the smallest p={smallest_p:.4f}. '
                'Holm is more powerful than Bonferroni but still conservative.'
            )

        return interpretations

    def _explain_bh(self, m: int, q_value: float) -> Dict[str, str]:
        """Generate Benjamini-Hochberg explanations"""
        return {
            'method_description': (
                'Benjamini-Hochberg controls the False Discovery Rate (FDR), '
                f'not FWER. FDR is the expected proportion of false positives '
                f'among rejected hypotheses. Target FDR = {q_value}.'
            ),
            'fdr_vs_fwer': (
                'FDR vs FWER:\n'
                '- FWER: Probability of ANY false positive (very strict)\n'
                '- FDR: Expected PROPORTION of false positives (more lenient)\n'
                f'- With FDR={q_value}: Expect {q_value*100:.0f}% false positives among discoveries'
            ),
            'advantages': (
                '- Much more powerful than FWER methods\n'
                '- Suitable for large numbers of tests\n'
                '- Allows some false positives for more discoveries\n'
                '- Ideal for exploratory analyses'
            ),
            'disadvantages': (
                '- Does not guarantee FWER control\n'
                '- Not appropriate for confirmatory trials\n'
                '- Requires independent or positively correlated tests'
            ),
            'when_to_use': (
                '- Exploratory research and discovery\n'
                '- Biomarker identification\n'
                '- Genomics and high-throughput screening\n'
                '- Hypothesis generation for confirmatory studies'
            )
        }

    def _explain_bh_algorithm(self) -> str:
        """Detailed BH algorithm explanation"""
        return (
            'Benjamini-Hochberg Algorithm:\n'
            '=============================\n'
            '1. Order p-values: p(1) ≤ p(2) ≤ ... ≤ p(m)\n'
            '2. Find largest k such that p(k) ≤ (k/m) × q\n'
            '3. Reject H(1), ..., H(k)\n'
            '4. Adjusted p-values: p_adj(i) = min(p(i) × m/i, 1)\n\n'
            'This controls the expected proportion of false discoveries at '
            'level q. More powerful than FWER methods for large m.'
        )

    def _interpret_bh(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str],
        q_value: float
    ) -> Dict[str, str]:
        """Generate BH interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        if num_sig == 0:
            interpretations['overall'] = (
                f'No discoveries at FDR level {q_value}. '
                'Consider increasing q-value or collecting more data.'
            )
        else:
            expected_fp = num_sig * q_value
            interpretations['overall'] = (
                f'{num_sig} discoveries at FDR {q_value}. '
                f'Expected false positives: {expected_fp:.1f}. '
                f'This is acceptable for exploratory analysis but '
                f'would require confirmation in a separate study.'
            )

        return interpretations

    def _explain_by(
        self,
        m: int,
        q_value: float,
        harmonic_sum: float
    ) -> Dict[str, str]:
        """Generate Benjamini-Yekutieli explanations"""
        return {
            'method_description': (
                'Benjamini-Yekutieli controls FDR under arbitrary dependence '
                f'by using a correction factor c(m) = Σ(1/k) ≈ {harmonic_sum:.2f}. '
                f'This makes it more conservative than BH by ~{harmonic_sum/np.log(m):.1f}×.'
            ),
            'when_needed': (
                'Use BY when:\n'
                '- Tests are strongly correlated\n'
                '- Unknown correlation structure\n'
                '- Valid FDR control is critical\n'
                '- Willing to sacrifice power for safety'
            ),
            'tradeoff': (
                f'BY vs BH:\n'
                f'- BY: Controls FDR under ANY dependence\n'
                f'- BH: Controls FDR under independence/positive dependence\n'
                f'- BY is ~{harmonic_sum/np.log(m):.1f}× more conservative\n'
                f'- Use BY if uncertain about correlation structure'
            )
        }

    def _interpret_by(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str],
        q_value: float
    ) -> Dict[str, str]:
        """Generate BY interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        if num_sig == 0:
            interpretations['overall'] = (
                f'No discoveries at FDR level {q_value} with BY correction. '
                'BY is conservative - consider BH if independence is plausible.'
            )
        else:
            interpretations['overall'] = (
                f'{num_sig} discoveries with conservative BY correction. '
                'These findings are robust to dependence but may be conservative.'
            )

        return interpretations

    def _explain_sidak(self, m: int, sidak_alpha: float) -> Dict[str, str]:
        """Generate Šidák explanations"""
        return {
            'method_description': (
                'Šidák correction provides exact FWER control for independent '
                f'tests using the formula α_sidak = 1 - (1 - α)^{{1/m}} = {sidak_alpha:.6f}. '
                'Slightly less conservative than Bonferroni.'
            ),
            'independence_requirement': (
                'CRITICAL: Šidák assumes test independence. '
                'Not valid for correlated endpoints or repeated measures.'
            ),
            'formula_comparison': (
                f'Bonferroni: α_adj = {self.alpha}/{m} = {self.alpha/m:.6f}\n'
                f'Šidák: α_adj = {sidak_alpha:.6f}\n'
                f'Gain: {((sidak_alpha - self.alpha/m) / (self.alpha/m) * 100):.1f}% more power'
            ),
            'advantages': (
                '- Exact FWER control under independence\n'
                '- More powerful than Bonferroni\n'
                '- Simple formula'
            ),
            'when_to_use': (
                '- Independent tests only\n'
                '- When slight power gain is valuable\n'
                '- Independent primary endpoints\n'
                '- Independent subgroup analyses'
            )
        }

    def _interpret_sidak(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str],
        sidak_alpha: float
    ) -> Dict[str, str]:
        """Generate Šidák interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        interpretations['overall'] = (
            f'{num_sig} tests significant at Šidák α={sidak_alpha:.6f}. '
            f'Assumes test independence - verify this assumption.'
        )

        return interpretations

    def _explain_hochberg(self, m: int, fwer: Dict) -> Dict[str, str]:
        """Generate Hochberg explanations"""
        return {
            'method_description': (
                'Hochberg is a step-up procedure that is more powerful than '
                'Holm when tests are independent. Starts with largest p-value '
                f'and works upward. More powerful than Holm for m={m} tests.'
            ),
            'algorithm': (
                'Hochberg Step-Up Algorithm:\n'
                '1. Sort p-values: p(1) ≤ p(2) ≤ ... ≤ p(m)\n'
                '2. Start from largest: Compare p(m) to α\n'
                '3. If p(m) ≤ α: Reject ALL\n'
                '4. Otherwise compare p(m-1) to α/2\n'
                '5. Continue upward until first significant'
            ),
            'advantages': (
                '- More powerful than Holm under independence\n'
                '- Still controls FWER exactly\n'
                '- Step-up is more efficient than step-down'
            ),
            'disadvantages': (
                '- Requires independence (unlike Holm)\n'
                '- Less powerful than Hommel\n'
                '- Not valid for correlated tests'
            ),
            'when_to_use': (
                '- Independent tests confirmed\n'
                '- Need more power than Holm\n'
                '- Confirmatory trials with independent endpoints'
            )
        }

    def _explain_hochberg_algorithm(self) -> str:
        """Detailed Hochberg algorithm explanation"""
        return (
            'Hochberg Step-Up Algorithm:\n'
            '========================\n'
            '1. Order p-values: p(1) ≤ p(2) ≤ ... ≤ p(m)\n'
            '2. For k = m down to 1:\n'
            '   a. Compare p(k) to α/(m-k+1)\n'
            '   b. If p(k) ≤ α/(m-k+1): REJECT H(1)...H(k), STOP\n'
            '   c. Otherwise continue to k-1\n'
            '3. If loop completes without rejection, reject none\n\n'
            'Step-up procedures are generally more powerful than step-down '
            'when tests are independent, as they can reject more hypotheses '
            'early in the process.'
        )

    def _interpret_hochberg(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str]
    ) -> Dict[str, str]:
        """Generate Hochberg interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        interpretations['overall'] = (
            f'{num_sig} tests significant with Hochberg. '
            'More powerful than Holm assuming independence.'
        )

        return interpretations

    def _explain_hommel(self, m: int, fwer: Dict) -> Dict[str, str]:
        """Generate Hommel explanations"""
        return {
            'method_description': (
                "Hommel\'s method provides exact FWER control and is generally "
                f"more powerful than Bonferroni, Holm, and Hochberg for m={m} tests. "
                "Uses a global test approach with closed testing."
            ),

    def _interpret_hommel(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
                significant: np.ndarray,
        test_names: List[str]
    ) -> Dict[str, str]:
        """Generate Hommel interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        interpretations['overall'] = (
            f'{num_sig} tests significant with Hommel. '
            'Hommel provides excellent power while maintaining FWER control.'
        )

        return interpretations

    def _explain_method(self, method: str, m: int) -> Dict[str, str]:
        """Generate explanations for any method"""
        explanations = {
            'bonferroni': self._explain_bonferroni(m, {}),
            'holm': self._explain_holm(m, {}),
            'fdr_bh': self._explain_bh(m, 0.05),
            'fdr_by': self._explain_by(m, 0.05, np.sum(1/np.arange(1, m+1))),
            'sidak': self._explain_sidak(m, 1 - (1 - self.alpha)**(1/m)),
            'hochberg': self._explain_hochberg(m, {}),
            'hommel': self._explain_hommel(m, {})
        }
        return explanations.get(method, {})

    def _interpret_general(
        self,
        p_values: np.ndarray,
        adjusted_pvals: np.ndarray,
        significant: np.ndarray,
        test_names: List[str],
        method: str
    ) -> Dict[str, str]:
        """Generate general interpretations"""
        num_sig = np.sum(significant)
        interpretations = {}

        interpretations['overall'] = (
            f'{num_sig} of {len(p_values)} tests significant after '
            f'{method.upper()} correction at α={self.alpha}.'
        )

        return interpretations

    def _explain_comparison(
        self,
        ranking: List[Tuple[str, int]],
        m: int
    ) -> Dict[str, str]:
        """Generate comparison explanations"""
        most_powerful = ranking[0][0]
        least_powerful = ranking[-1][0]

        return {
            'power_ranking': (
                f'Methods ranked by power (number significant):\n' +
                '\n'.join([f"{i+1}. {method}: {num_sig} significant"
                          for i, (method, num_sig) in enumerate(ranking)])
            ),
            'tradeoffs': (
                f'- Most powerful: {most_powerful} (may not control FWER)\n'
                f'- Least powerful: {least_powerful} (most conservative)\n'
                f'- Holm is often the best compromise for FWER control\n'
                f'- BH is best for exploratory FDR control'
            ),
            'clinical_considerations': (
                '- Confirmatory trials: Use FWER methods (Bonferroni, Holm)\n'
                '- Exploratory research: Use FDR methods (BH)\n'
                '- Primary endpoints: Require strict FWER control\n'
                '- Secondary endpoints: Can use less conservative methods'
            )
        }

    # ==============================================================================
    # CLINICAL GUIDANCE METHODS - FDA/EMA recommendations
    # ==============================================================================

    def _clinical_guidance_bonferroni(self) -> Dict[str, str]:
        """FDA/EMA guidance for Bonferroni"""
        return {
            'fda_guidance': (
                'FDA Multiplicity Guidance (2017): "The Bonferroni method '
                'ensures FWER control and is appropriate for confirmatory trials '
                'with a small number of primary endpoints."'
            ),
            'ema_guidance': (
                'EMA Guideline (2016): "Bonferroni is acceptable for multiple '
                'testing adjustments when the number of comparisons is small."'
            ),
            'clinical_application': (
                '- Multiple primary endpoints (≤5)\n'
                '- Dose-response studies\n'
                '- Multiple time points\n'
                '- When simplicity is valued over power'
            ),
            'example_trial': (
                'Phase III trial with 3 primary endpoints (pain relief, '
                'function improvement, quality of life). Apply Bonferroni: '
                'α = 0.05/3 = 0.0167 per endpoint.'
            )
        }

    def _clinical_guidance_holm(self) -> Dict[str, str]:
        """FDA/EMA guidance for Holm"""
        return {
            'fda_guidance': (
                'FDA: "Holm is recommended when more power is desired than '
                'Bonferroni while maintaining FWER control. Suitable for '
                'secondary endpoint testing."'
            ),
            'ema_guidance': (
                'EMA: "Stepwise procedures like Holm are preferred over '
                'Bonferroni for testing multiple secondary endpoints due to '
                'improved power."'
            ),
            'clinical_application': (
                '- Hierarchical secondary endpoint testing\n'
                '- Multiple dose comparisons\n'
                '- When more power is needed\n'
                '- Default choice for FWER control'
            ),
            'example_trial': (
                'Trial with 10 secondary endpoints. Use Holm step-down: '
                'test smallest p-value at α=0.005, next at α=0.0056, etc. '
                'More powerful than Bonferroni (α=0.005 for all).'
            )
        }

    def _clinical_guidance_bh(self) -> Dict[str, str]:
        """FDA/EMA guidance for BH"""
        return {
            'fda_guidance': (
                'FDA: "FDR methods like Benjamini-Hochberg may be appropriate '
                'for exploratory analyses and biomarker discovery where some '
                'false positives are acceptable. Not for confirmatory trials."'
            ),
            'ema_guidance': (
                'EMA: "FDR control is not appropriate for confirmatory trials '
                'but may be used in exploratory research and hypothesis '
                'generation."'
            ),
            'clinical_application': (
                '- Exploratory biomarker studies\n'
                '- Gene expression profiling\n'
                '- High-throughput screening\n'
                '- Hypothesis generation'
            ),
            'example_trial': (
                'Exploratory biomarker study with 1000 genes. Use BH FDR=0.10 '
                'to identify 50 candidate genes for validation in a '
                'confirmatory study.'
            )
        }

    def _clinical_guidance_by(self) -> Dict[str, str]:
        """FDA/EMA guidance for BY"""
        return {
            'fda_guidance': (
                'FDA: "Benjamini-Yekutieli provides FDR control under '
                'dependence and may be used when tests are correlated. More '
                'conservative than BH."'
            ),
            'ema_guidance': (
                'EMA: "For correlated endpoints, use methods that account for '
                'dependence such as BY or resampling-based procedures."'
            ),
            'clinical_application': (
                '- Correlated biomarker panels\n'
                '- Repeated measures\n'
                '- Unknown correlation structure\n'
                '- When valid FDR control is critical'
            ),
            'example_trial': (
                'Study of 50 correlated cytokines. Use BY to ensure valid '
                'FDR control despite strong correlations between cytokines.'
            )
        }

    def _clinical_guidance_sidak(self) -> Dict[str, str]:
        """FDA/EMA guidance for Šidák"""
        return {
            'fda_guidance': (
                'FDA: "Šidák is acceptable when tests are independent '
                'and provides slightly more power than Bonferroni. '
                'Verify independence before use."'
            ),
            'ema_guidance': (
                'EMA: "Šidák may be used when test independence can be '
                'demonstrated. Otherwise, use Bonferroni or Holm."'
            ),
            'clinical_application': (
                '- Independent primary endpoints\n'
                '- Independent subgroup analyses\n'
                '- When slight power gain matters\n'
                '- Meta-analysis of independent trials'
            ),
            'example_trial': (
                'Trial with 2 independent primary endpoints (e.g., '
                'overall survival and progression-free survival in different '
                'populations). Šidák α = 1 - (1-0.05)^(1/2) = 0.0253.'
            )
        }

    def _clinical_guidance_hochberg(self) -> Dict[str, str]:
        """FDA/EMA guidance for Hochberg"""
        return {
            'fda_guidance': (
                'FDA: "Hochberg is appropriate for independent tests and '
                'provides more power than Holm. Not suitable for correlated '
                'endpoints."'
            ),
            'ema_guidance': (
                'EMA: "Step-up procedures like Hochberg can be more powerful '
                'than step-down when independence holds. Use with caution."'
            ),
            'clinical_application': (
                '- Independent secondary endpoints\n'
                '- Confirmatory trials with independence\n'
                '- When maximum power is needed\n'
                '- Independent dose comparisons'
            ),
            'example_trial': (
                'Dose-response study with 3 independent dose comparisons. '
                'Hochberg provides more power than Holm for detecting dose '
                'effects.'
            )
        }

    def _clinical_guidance_hommel(self) -> Dict[str, str]:
        """FDA/EMA guidance for Hommel"""
        return {
            'fda_guidance': (
                'FDA: "Hommel provides excellent power while maintaining '
                'FWER control. Suitable for complex multiplicity problems "
                "with moderate numbers of tests."'
            ),
            'ema_guidance': (
                'EMA: "Hommel is a powerful closed testing procedure that '
                'may be used when computational resources permit."'
            ),
            'clinical_application': (
                '- Complex multiplicity problems\n'
                '- Multiple primary and secondary endpoints\n'
                '- When maximum power with FWER control is needed\n'
                '- Moderate number of tests (<1000)'
            ),
            'example_trial': (
                'Phase III trial with hierarchical testing of primary, '
                'key secondary, and other secondary endpoints. Hommel provides '
                'optimal power across all levels.'
            )
        }

    def _clinical_guidance_fwer(self) -> Dict[str, str]:
        """FDA/EMA guidance for FWER"""
        return {
            'fda_guidance': (
                'FDA: "Family-wise error rate control is required for '
                'confirmatory trials. The probability of any false positive '
                'among all tests must be controlled at α=0.05."'
            ),
            'ema_guidance': (
                'EMA: "FWER control is mandatory for primary efficacy '
                'endpoints in Phase III confirmatory trials. FDR may be used '
                'for exploratory analyses."'
            ),
            'clinical_importance': (
                '- Prevents false claims of efficacy\n'
                '- Protects patient safety\n'
                '- Maintains study integrity\n'
                '- Regulatory requirement for approval'
            ),
            'when_required': (
                '- All confirmatory Phase III trials\n'
                '- Primary endpoint analysis\n'
                '- Claims for regulatory approval\n'
                '- Labeling statements'
            )
        }

    def _clinical_guidance_comparison(self) -> Dict[str, str]:
        """FDA/EMA guidance for method comparison"""
        return {
            'method_selection_principles': (
                'FDA/EMA Multiplicity Guidance Principles:\n'
                '1. Pre-specify multiplicity adjustment strategy\n'
                '2. Justify method choice based on trial objectives\n'
                '3. Control appropriate error rate (FWER or FDR)\n'
                '4. Consider power and clinical relevance'
            ),
            'confirmatory_trials': (
                'For Confirmatory Trials:\n'
                '- Must control FWER (α=0.05)\n'
                '- Recommended: Holm or Bonferroni\n'
                '- Alternative: Hochberg (if independent), Hommel (if feasible)\n'
                '- NOT appropriate: FDR methods'
            ),
            'exploratory_trials': (
                'For Exploratory Trials:\n'
                '- May control FDR (q=0.10-0.20)\n'
                '- Recommended: Benjamini-Hochberg\n'
                '- If dependent: Benjamini-Yekutieli\n'
                '- Findings require confirmation'
            ),
            'decision_tree': (
                'Decision Tree:\n'
                'Confirmatory? → Yes → FWER → Holm (default)\n'
                '                              → Independent? → Yes → Hochberg/Sidak\n'
                '                              → Many tests? → Hommel\n'
                '                 → No → FDR → Independent? → Yes → BH\n'
                '                              → Unknown → BY'
            )
        }

    def _generate_method_recommendations(
        self,
        p_values: np.ndarray,
        m: int
    ) -> List[str]:
        """Generate method recommendations based on data"""
        recommendations = []

        # Assess p-value distribution
        very_small_p = np.sum(p_values < 0.001)
        small_p = np.sum(p_values < 0.01)
        moderate_p = np.sum(p_values < 0.05)

        if m <= 5:
            recommendations.append(
                f"Small number of tests (m={m}): Bonferroni is simple and "
                "appropriate. Consider Holm for slightly more power."
            )
        elif m <= 20:
            recommendations.append(
                f"Moderate number of tests (m={m}): Holm is recommended as "
                "default FWER control. Hochberg if tests are independent."
            )
        else:
            recommendations.append(
                f"Large number of tests (m={m}): Consider FDR methods (BH) "
                "for exploratory analysis. Hommel for FWER if computationally feasible."
            )

        if very_small_p >= 3:
            recommendations.append(
                f"{very_small_p} very small p-values detected (<0.001). "
                "Strong evidence suggests findings may be robust to correction."
            )

        if self.independence:
            recommendations.append(
                "Independence assumed: Šidák, Hochberg, and BH provide "
                "more power than Bonferroni, Holm, and BY respectively."
            )
        else:
            recommendations.append(
                "Dependence possible: Use methods valid under correlation "
                "(Bonferroni, Holm, Hommel, BY) rather than Šidák or Hochberg."
            )

        return recommendations

    # ==============================================================================
    # UTILITY METHODS - Calculations and assessments
    # ==============================================================================

    def _compare_by_vs_bh(self, p_values: np.ndarray, m: int) -> Dict[str, Any]:
        """Compare BY vs BH"""
        bh_reject = smm.multipletests(p_values, alpha=self.alpha, method='fdr_bh')[0]
        by_reject = smm.multipletests(p_values, alpha=self.alpha, method='fdr_by')[0]

        return {
            'bh_significant': int(np.sum(bh_reject)),
            'by_significant': int(np.sum(by_reject)),
            'difference': int(np.sum(bh_reject) - np.sum(by_reject)),
            'interpretation': 'BY is more conservative, especially for larger m'
        }

    def _compare_sidak_vs_bonferroni(self, m: int) -> Dict[str, float]:
        """Compare Šidák vs Bonferroni"""
        bonf_alpha = self.alpha / m
        sidak_alpha = 1 - (1 - self.alpha) ** (1 / m)

        return {
            'bonferroni_alpha': bonf_alpha,
            'sidak_alpha': sidak_alpha,
            'power_gain_percent': ((sidak_alpha - bonf_alpha) / bonf_alpha) * 100
        }

    def _compare_hochberg_vs_holm(self, p_values: np.ndarray, m: int) -> Dict[str, int]:
        """Compare Hochberg vs Holm"""
        holm_reject = smm.multipletests(p_values, alpha=self.alpha, method='holm')[0]
        hoch_reject = smm.multipletests(p_values, alpha=self.alpha, method='hochberg')[0]

        return {
            'holm_significant': int(np.sum(holm_reject)),
            'hochberg_significant': int(np.sum(hoch_reject)),
            'difference': int(np.sum(hoch_reject) - np.sum(holm_reject))
        }

    def _compare_hommel_vs_bonferroni(self, p_values: np.ndarray, m: int) -> Dict[str, int]:
        """Compare Hommel vs Bonferroni"""
        bonf_reject = smm.multipletests(p_values, alpha=self.alpha, method='bonferroni')[0]
        homm_reject = smm.multipletests(p_values, alpha=self.alpha, method='hommel')[0]

        return {
            'bonferroni_significant': int(np.sum(bonf_reject)),
            'hommel_significant': int(np.sum(homm_reject)),
            'power_gain': int(np.sum(homm_reject) - np.sum(bonf_reject))
        }

    def _assess_conservatism(self, method: str) -> str:
        """Assess method conservativism"""
        conservatism_order = [
            ('bonferroni', 'Most Conservative'),
            ('fdr_by', 'Very Conservative'),
            ('holm', 'Conservative'),
            ('sidak', 'Moderate'),
            ('hochberg', 'Moderate'),
            ('hommel', 'Less Conservative'),
            ('fdr_bh', 'Least Conservative (FWER)')
        ]

        for m, level in conservatism_order:
            if m == method:
                return level
        return 'Unknown'

    def _requires_independence(self, method: str) -> bool:
        """Check if method requires independence"""
        return method in ['sidak', 'hochberg', 'fdr_bh']

    def _suitability_confirmatory(self, method: str) -> str:
        """Check suitability for confirmatory trials"""
        fwer_methods = ['bonferroni', 'holm', 'sidak', 'hochberg', 'hommel']
        return 'Yes' if method in fwer_methods else 'No'

    def _suitability_exploratory(self, method: str) -> str:
        """Check suitability for exploratory trials"""
        fdr_methods = ['fdr_bh', 'fdr_by']
        return 'Yes' if method in fdr_methods else 'Yes (conservative)'

    def _generate_warnings(self, method: str, m: int) -> List[str]:
        """Generate appropriate warnings"""
        warnings_list = []

        if method in ['sidak', 'hochberg']:
            warnings_list.append(
                'CRITICAL: This method assumes test independence. '
                'Not valid for correlated endpoints or repeated measures.'
            )

        if method in ['fdr_bh', 'fdr_by']:
            warnings_list.append(
                'FDR methods do not control FWER. Not appropriate for '
                'confirmatory trials or primary endpoints. Use only for '
                'exploratory analyses.'
            )

        if method == 'fdr_by':
            warnings_list.append(
                f'BY is very conservative (harmonic sum ~{np.sum(1/np.arange(1, m+1)):.1f}). '
                'Consider BH if tests are independent.'
            )

        if m > 100 and method in ['bonferroni', 'holm']:
            warnings_list.append(
                f'Large number of tests (m={m}). Consider FDR methods for '
                'exploratory analysis or Hommel for FWER control.'
            )

        if method == 'bonferroni':
            warnings_list.append(
                'Bonferroni is conservative. Consider Holm for more power '
                'while maintaining FWER control.'
            )

        return warnings_list

    def _log_analysis(self, method: str, results: Dict):
        """Log analysis for audit trail"""
        log_entry = {
            'method': method,
            'timestamp': results.get('timestamp'),
            'alpha': self.alpha,
            'num_tests': results.get('num_tests', 0),
            'num_significant': results.get('num_significant', 0)
        }
        self.analysis_history.append(log_entry)


def create_example_usage():
    """Create example usage for demonstration"""
    print("=" * 80)
    print("Multiplicity Control Module - Example Usage")
    print("=" * 80)
    print()

    # Initialize
    mc = MultiplicityControl(alpha=0.05)

    # Example 1: Multiple endpoints in clinical trial
    print("Example 1: Multiple Primary Endpoints")
    print("-" * 40)
    endpoints = ['Pain Relief', 'Function Improvement', 'Quality of Life']
    pvalues = [0.01, 0.02, 0.03]
    result = mc.bonferroni_correction(pvalues, endpoints)
    print(f"Adjusted P-values: {result['adjusted_pvalues']}")
    print(f"Significant: {result['significant']}")
    print()

    # Example 2: Compare all methods
    print("Example 2: Method Comparison")
    print("-" * 40)
    pvalues = [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]
    comparison = mc.compare_correction_methods(pvalues)
    print(f"Power Ranking: {comparison['power_ranking']}")
    print()

    # Example 3: FDR for exploratory analysis
    print("Example 3: FDR Control for Biomarker Discovery")
    print("-" * 40)
    biomarkers = [f"Gene_{i}" for i in range(1, 101)]
    np.random.seed(42)
    pvalues = np.random.beta(0.5, 5, 100)
    result = mc.benjamini_hochberg_fdr(pvalues, biomarkers, q_value=0.10)
    print(f"Discoveries at FDR=0.10: {result['num_significant']}")
    print()


if __name__ == "__main__":
    create_example_usage()
